{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf7b449-0bf8-44a8-8495-48569ab9b36f",
   "metadata": {},
   "source": [
    " Bags of words\n",
    "===\n",
    "**Computational social sciences**\n",
    "\n",
    "---\n",
    "In this Notebook we will show how to extract bags of words to perform dyachronic analysis of historical texts.\n",
    "\n",
    "---\n",
    "\n",
    "## Section 1: Using word lists ...\n",
    "\n",
    "... from psychometric tools and obtain synonyms and hyponyms using WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a067a-c12b-495c-9f01-94db224dd04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "\n",
    "#nltk.download('all') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f224e-2b65-43c3-8ec5-92d28acf2f73",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d355f-a4dd-4471-8c6e-f77d3bf224ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_meanings(word_list):\n",
    "    \"\"\"\n",
    "    Generates a list of word meanings/definitions\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word_list : a list of words\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list with word meanings and definitions.\n",
    "\n",
    "    \"\"\"\n",
    "    word_meaning_def = []\n",
    "    \n",
    "    # iterate over words in the word_base list\n",
    "    for word in word_list:\n",
    "\n",
    "      ## iterate over different meanings of the word synsets\n",
    "      for meaning in wn.synsets(word, pos=wn.NOUN+wn.VERB+wn.ADJ):\n",
    "          #print(meaning)\n",
    "          #print(meaning.definition())\n",
    "          #print('\\n')\n",
    "          word_meaning_def.append([word, meaning, meaning.definition()])\n",
    "    \n",
    "    # remove duplicates  \n",
    "    meanings_list = [] \n",
    "    [meanings_list.append(x) for x in word_meaning_def if x not in meanings_list]\n",
    "            \n",
    "    return(meanings_list)\n",
    "\n",
    "\n",
    "def word_check(list_pre):\n",
    "    \"\"\"\n",
    "    For manually checking each word for relevance and removing irrelevant terms.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list_pre : a list of words\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list_post : a list of words after checks\n",
    "    \n",
    "    Use\n",
    "    ------\n",
    "    For each word, press 1 if it is relevant, 0 otherwise\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    list_post = []\n",
    "    \n",
    "    for item in list_pre:\n",
    "        \n",
    "        print(item)\n",
    "        x = input()\n",
    "        \n",
    "        if x == '1':\n",
    "            list_post.append(item)\n",
    "            \n",
    "    return(list_post)\n",
    "\n",
    "\n",
    "def synonyms_hyponyms(meaning_list, languages):\n",
    "    \"\"\"\n",
    "    Generates synonyms and hyponyms from pruned word base.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    meaning_list : list of meanings\n",
    "    languages : languages for search, e.g. ['eng']\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list of words in specified languages, including synomyns and hyponyms.\n",
    "\n",
    "    \"\"\"\n",
    "  \n",
    "    word_lists = []\n",
    "    sysnet = []\n",
    "    \n",
    "    ## Create a list with just sysnet meanings\n",
    "    i = 0\n",
    "    while i < len(meaning_list):\n",
    "        x = meaning_list[i][1]\n",
    "        sysnet.append(x)\n",
    "        i += 1\n",
    "\n",
    "    for language in languages: # loop over languages\n",
    "    \n",
    "        word_list = []\n",
    "\n",
    "        for word in sysnet: # loop over words in sysnet list\n",
    "                    \n",
    "            for synonym in word.lemmas(language): # synonyms\n",
    "                if synonym.name() not in word_list:\n",
    "                        word_list.append(synonym.name())\n",
    "\n",
    "            for hyponym in word.hyponyms(): # hyponyms\n",
    "                for synonym_of_hyponym in hyponym.lemmas(language):\n",
    "                    if synonym_of_hyponym.name() not in word_list:\n",
    "                        word_list.append(synonym_of_hyponym.name())\n",
    "\n",
    "    word_lists += [sorted(word_list)] # add language-specific list to global list, sorting alphabetically\n",
    "\n",
    "    for lst in word_lists: # combine lists for each language\n",
    "        return(lst)\n",
    "    \n",
    "\n",
    "def bag_of_words(word_list):\n",
    "    \"\"\"\n",
    "    Extracts words and removes duplicates, creating the final bag of words.\n",
    "    \"\"\"\n",
    "        \n",
    "    full_list = []\n",
    "\n",
    "    for i in word_list:\n",
    "        x = i[0]\n",
    "        full_list.append(x)\n",
    "    \n",
    "    final_list = [] \n",
    "    [final_list.append(x) for x in full_list if x not in final_list]\n",
    "    \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaafcc8-349e-4724-a9b1-386530f4706e",
   "metadata": {},
   "source": [
    "### Seed words related to financial behaviors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b683992-afd2-4b2b-87fb-824a57077543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_base_financial = ['earn', 'income', 'compensation', 'livelihood', 'pay', 'paycheck', 'salary', 'wage', 'save', 'assets', \n",
    "                  'profit', 'accumulation', 'deposit', 'installment', 'wealth', 'spend', 'purchase', 'consume', 'payment', \n",
    "                  'fund', 'invest', 'stockmarket', 'stock', 'bond', 'securities', 'dividends', 'shareholder', 'portfolio'\n",
    "                  'debt', 'liability', 'credit', 'loan', 'money', 'cash', 'currency', 'bills', 'coins', 'rich', 'poor', \n",
    "                  'bank', 'economy', 'financial']\n",
    "\n",
    "# Create a list of meanings and definitions\n",
    "financial_list_meanings = generate_meanings(word_base_financial)\n",
    "\n",
    "# Create a pruned version of the list by removing irrelevant words\n",
    "financial_list_pruned = word_check(financial_list_meanings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f531bb37-21dc-4344-bdcc-e0828bfdd5ac",
   "metadata": {},
   "source": [
    "#### Optional: look at pruned word list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c020b4-78e9-4c1b-9f3b-327256b0fa45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(financial_list_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac945492-b9b1-4c38-ab3c-0ffecc307012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FINANCIAL TERMS\n",
    "\n",
    "# Generate the list of synonyms and hyponyms\n",
    "languages = ['eng']\n",
    "financial_list_syn_hyp = synonyms_hyponyms(financial_list_pruned, languages)\n",
    "\n",
    "# Generate meanings\n",
    "financial_list_meanings = generate_meanings(financial_list_syn_hyp)\n",
    "\n",
    "# Exclude irrelevant words\n",
    "# type 0 to exclude, 1 to include\n",
    "financial_list = word_check(financial_list_meanings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31721c3-7e59-482a-b430-65ce65cdf3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "\n",
    "print(financial_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef4e0a-7767-4f02-8946-c2bdf6bb01c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FINANCIAL TERMS\n",
    "# Create final word list for next steps.\n",
    "\n",
    "final_financial_list = bag_of_words(financial_list)\n",
    "#final_Financial_list = word_check(final_financial_list)\n",
    "\n",
    "# Optional: check final list\n",
    "#print(final_Financial_list)\n",
    "print(final_financial_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47610f3-bdb9-4c1b-a774-214275c98986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare lists for inter-rater reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a204e68c-417d-4d0d-8121-59c63cbbd06f",
   "metadata": {
    "id": "ZCk2ZCbDchya"
   },
   "source": [
    "---\n",
    "# Section 2: Generate a semantic vector map with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b857c2-e334-4cfc-a747-80f3488d5f01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AqHA_VEac02j",
    "outputId": "eccc182c-06f4-4b69-fe31-a00a59b956de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import os\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c47509b-51b6-4553-8b48-e6a20c0f1e16",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec495b7b-5ce0-42d3-a169-c7f4bf9d222e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def literary_words_list(file_path):\n",
    "    \"\"\"\n",
    "    Function to select .txt files and store them as a list of words, to use as input to the function WordVec\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : a file path where .txt files are located (e.g. '/path/to/texts')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list of the words in the files\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Specify root folder for file search\n",
    "    os.chdir(file_path)\n",
    "    root_folder = os.getcwd()\n",
    "\n",
    "    # Create list for clean sentences\n",
    "    words_list = []\n",
    "\n",
    "    # Iterates over the path, folders and subfolders looking for txt files\n",
    "    for path, subdirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if '.txt' in file and 'model' not in file:\n",
    "                print(file)\n",
    "                name = os.path.join(path, file)\n",
    "                file_text = open(name, encoding = 'utf-8').read()\n",
    "\n",
    "                # Creates a list of paragraphs - lines\n",
    "                text_list_paragraphs = file_text.split('\\n')\n",
    "\n",
    "                # Clean the paragraphs further -- getting read of \\r at the end of the line\n",
    "                for paragraph in text_list_paragraphs:\n",
    "                \n",
    "                    #paragraph = paragraph.replace('\\r', '')\n",
    "\n",
    "                    # Add the paragraphs to the word2vec input list\n",
    "                    words_list += [paragraph.split(' ')]\n",
    "            \n",
    "    return words_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaba6d6-5e64-4d3b-ab18-2ceca93c93c7",
   "metadata": {},
   "source": [
    "## Create list of words from .txt files of literary plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac217947-6f83-4517-a172-267e5540fa70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word2vec_input = literary_words_list('c:\\\\Users\\\\Maria\\\\Dropbox\\\\Maria Brackin\\\\Finance and Text Analysis\\\\texts\\\\english early modern')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f43151b-f43f-4731-800f-ba81a476579c",
   "metadata": {},
   "source": [
    "## Build and save the vector space with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ea48a-dec8-4d60-ab71-cc1cc3b8d578",
   "metadata": {
    "id": "dSb5F5HT6lAC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SentenceCorpus = word2vec_input\n",
    "word2vec_output = Word2Vec(SentenceCorpus, min_count=1)\n",
    "\n",
    "# save to file\n",
    "word2vec_output.save('w2v_model.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d6698-e625-43d7-8b7d-6320cd8ff792",
   "metadata": {
    "id": "cViUsz8Z6kFU"
   },
   "source": [
    "---\n",
    "# Section 3 Use the vector semantic map ...\n",
    "...to evaluate if the bags of words created in section 1 are ecologically valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b39652-fa5e-4de9-a92f-9b0250eeb879",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e82b7a0-4e52-4d37-83f5-0a775d120395",
   "metadata": {
    "id": "I3SgEEzw-YQD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_word2vec_list(word_list,model):\n",
    "    \"\"\"\n",
    "    Uses word2vec to find the 10 semantically most similar words to each seed word in word_list\n",
    "    \"\"\"\n",
    "    \n",
    "    list_of_word2vec_lists = []\n",
    "    for word in word_list:\n",
    "        try:\n",
    "\n",
    "            ## here is the crucial line - we are using the model that we trained to get the most similar words within our corpus\n",
    "            list_vects = model.wv.most_similar([word],topn=10)\n",
    "\n",
    "            new_list = []\n",
    "            new_list += [word]\n",
    "            for item in list_vects:\n",
    "                word1 = item[0]\n",
    "                new_list += [word1]\n",
    "\n",
    "            #print(new_list)\n",
    "            #print('\\n')\n",
    "            list_of_word2vec_lists += [new_list]\n",
    "\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return(list_of_word2vec_lists)\n",
    "\n",
    "\n",
    "def choose_word2vec_list(w2v_word_list):\n",
    "    \"\"\"\n",
    "    Checks word2vec list of 10 most similar words\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    w2v_word_list : a list of words\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list of ecologically valid words \n",
    "    \n",
    "    Use\n",
    "    ------\n",
    "    For the 10 lists of words, choose the number of those that have meanings coherent with the topic\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    indices = []\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    for w2v_list in w2v_word_list:\n",
    "        \n",
    "        print(index, w2v_list) \n",
    "        x = input()\n",
    "        if x == '1':\n",
    "            indices.append(index)\n",
    "        index += 1\n",
    "    \n",
    "    ## chose from the word2vec outputs, the lists that seem to have clouds of meanings coherent with prosociality\n",
    "    ## in this example we can chose, for instance (among others) indexes 3,6,9,11,13 and 14\n",
    "\n",
    "    relevant_w2v_words = list(w2v_word_list[i] for i in indices)\n",
    "\n",
    "    return [item for sublist in relevant_w2v_words for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf54c8c6-7f18-464e-90c2-8d83056c2ecc",
   "metadata": {},
   "source": [
    "## Load vector space for english in the early modern period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14521b47-bba3-4a4e-9128-a4d0fc21d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = Word2Vec.load('w2v_model.txt')\n",
    "\n",
    "\n",
    "final_financial_list = ['Maundy_money', 'absorb', 'account_payable', 'accounts_receivable', 'accumulation', 'acquirer', 'affluence', 'afford', 'amortisation', 'amortization', 'amount', 'amount_of_money', 'ante_up', 'arrears', 'assets', 'bank', 'bank_bill', 'bank_building', 'bank_deposit', 'bank_line', 'bank_loan', 'bank_note', \"banker's_bill\", 'banking_company', 'banking_concern', 'banknote', 'bankroll', 'bargain', 'bawbee', 'bear', 'benefit', 'big_bucks', 'big_money', 'bill', 'bond', 'bond_certificate', 'bond_issue', 'boodle', 'bread', 'bread_and_butter', 'bring_home', 'bring_in', 'budget', 'bundle', 'buy', 'buy_back', 'buy_food', 'buy_into', 'buy_out', 'buy_up', 'buyback', 'buying', 'cache', 'call_loan', 'capital', 'cash', 'cash_flow', 'cash_in', 'cash_in_hand', 'change', 'charge', 'cheap_money', 'chickenfeed', 'chump_change', 'cleanup', 'clear', 'coin', 'coinage', 'cold_cash', 'comforts', 'commercial_bank', 'commercial_credit', 'commit', 'consume', 'consumer_loan', 'credit', 'credit_line', 'credit_union', 'crown', 'currency', 'current_assets', 'debenture', 'debt', 'deep_pocket', 'deferred_payment', 'defray', 'defrayal', 'defrayment', 'demand_deposit', 'demand_loan', 'denier', 'deplete', 'deposit', 'direct_loan', 'disbursal', 'disburse', 'disbursement', 'disposable_income', 'dissipate', 'dividend', 'divvy', 'dough', 'down_payment', 'ducat', 'earn', 'earning_per_share', 'earnings', 'easy_money', 'economic_system', 'economise', 'economize', 'economy', 'economy_of_scale', 'eightpence', 'eke_out', 'equity', 'exhaust', 'expend', 'farthing', 'final_payment', 'finance', 'finances', 'financial', 'financial_obligation', 'fiscal', 'fivepence', 'folding_money', 'fool_away', 'foot', 'fourpence', 'free_enterprise', 'fritter', 'fritter_away', 'frivol_away', 'fund', 'funds', 'gain', 'gelt', 'give_back', 'government_income', 'government_note', 'government_revenue', 'government_security', 'gravy_train', 'greenback', 'groat', 'gross', 'gross_profit', 'gross_profit_margin', 'gross_revenue', 'gross_sales', 'growth_stock', 'guinea', \"ha'penny\", 'half-pay', 'half_crown', 'halfpenny', 'hard_cash', 'hard_currency', 'hedge_fund', 'hedgefund', 'hive_up', 'hoard', 'hole_card', 'home_equity_credit', 'home_equity_loan', 'home_loan', 'homeless', 'immediate_payment', 'impulse-buy', 'income', 'indebtedness', 'industrialism', 'inherited_wealth', 'installment', 'installment_credit', 'installment_loan', 'invest', 'investment', 'investment_funds', 'invoice', 'job', 'keep', 'laissez-faire_economy', 'lavish', 'lay_aside', 'lay_away', 'lay_out', 'letter_of_credit', 'letter_security', 'liability', 'limited_liability', 'line_of_credit', \"line_one's_pockets\", 'liquid_assets', 'liquidate', 'listed_security', 'livelihood', 'living', 'living_wage', 'loan', 'lucre', 'lump_sum', 'luxuriate', 'luxuriousness', 'luxury', 'maintenance', 'make', 'margin', 'market_economy', 'markup', 'material_resource', 'meal_ticket', 'megabucks', 'member_bank', 'merchant_bank', 'metal_money', 'minimum_wage', 'mintage', 'misspend', 'mixed_economy', 'monetary_fund', 'monetary_resource', 'money', 'moolah', 'mortgage_loan', 'mutual_fund', 'needy', 'nest_egg', 'net_income', 'net_profit', 'net_sales', 'nickel-and-dime', 'ninepence', 'non-market_economy', 'note', 'opulence', 'ordinary_shares', 'outlay', 'overage', 'overpay', 'overpayment', 'overspend', 'paper_currency', 'paper_money', 'pay', 'pay_cash', 'pay_envelope', 'pay_off', 'pay_out', 'pay_packet', 'pay_up', 'payable', 'paycheck', 'payment', 'payoff', 'payroll_check', 'pecuniary_resource', 'pelf', 'penny', 'penny-pinch', 'pension_fund', 'per_capita_income', 'personal_credit_line', 'personal_income', 'personal_line_of_credit', 'personal_loan', 'petty_cash', 'pick_up', 'pile', 'pin_money', 'pittance', 'pocket_money', 'poor', 'poor_people', 'premium', 'prepay', 'prepayment', 'proceeds', 'profit', 'profits', 'protection', 'pull_in', 'purchase', 'purchasing', 'quick_assets', 'quick_buck', 'quittance', 'rake_in', 'ready_cash', 'ready_money', 'realise', 'realize', 'receivables', 'recompense', 'redeem', 'redeposit', 'refund', 'regular_payment', 'remission', 'remit', 'remitment', 'remittal', 'remittance', 'remunerate', 'remuneration', 'rental_income', 'repay', 'repayment', 'repurchase', 'reserve', 'reserve_assets', 'reserve_bank', 'resource', 'retrenchment', 'return', 'reward', 'rich', 'rich_people', 'richness', 'salary', 'sales', 'save', 'save_up', 'saving', 'savings', 'scrimp', 'secured_bond', 'security', 'security_deposit', 'shareholder', 'shareowner', 'shekels', 'shilling', 'shinplaster', 'shoot', 'shower', 'sick_pay', 'sixpence', 'skimp', 'small_change', 'specie', 'spend', 'spending', 'spending_money', 'splurge', 'squander', 'stash', 'state_bank', 'sterling', 'stint', 'stock', 'stock_certificate', 'stock_dividend', 'stockholder', 'stockpile', 'subscribe', 'subscribe_to', 'subscription', 'subsidisation', 'subsidization', 'subsistence', 'sufficiency', 'sum', 'sum_of_money', 'sumptuousness', 'support', 'support_payment', 'surcharge', 'sustenance', 'take-home_pay', 'take_home', 'take_in', 'takings', 'tenpence', 'threepence', 'thriftiness', \"tighten_one's_belt\", 'time_loan', 'token_money', 'token_payment', 'treasury_stock', 'trifle', 'trifle_away', 'trust_fund', 'tuppence', 'turn_a_nice_penny', 'turn_a_profit', 'twopence', 'undercharge', 'underpay', 'underpayment', 'underspend', 'unearned_income', 'unearned_revenue', 'use_up', 'wage', 'wampum', 'wanton', 'wanton_away', 'ware', 'waste', 'wealth', 'wealthiness', 'working_capital', 'yield']\n",
    "\n",
    "# create lists of ecologically valid words \n",
    "#list_of_financial_w2v = get_word2vec_list(final_Financial_list, model)\n",
    "list_of_financial_w2v = get_word2vec_list(final_financial_list, model)\n",
    "\n",
    "# choose most relevant lists of words\n",
    "# type 0 to exclude, 1 to include\n",
    "\n",
    "financial_BoW = choose_word2vec_list(list_of_financial_w2v)\n",
    "\n",
    "print(list(set(financial_BoW)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0377fe94-9617-43b3-9f5c-4093de706fc6",
   "metadata": {},
   "source": [
    "## Check words again using word_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b13df9-f287-40fe-854f-51979f16b6ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Financial_BoW = word_check(financial_BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b56a2a-d06f-41e6-9f81-d04612870396",
   "metadata": {},
   "source": [
    "## Final list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391ecd3c-3bc3-4707-a5bd-1b8005ec0091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "FINANCIAL_BoW = list(set(Financial_BoW))\n",
    "\n",
    "## Final bags of words for frequency analyses\n",
    "print('financial terms\\n\\n', FINANCIAL_BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0da3c1-9fa1-452f-bf68-914036493e9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## See next script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
