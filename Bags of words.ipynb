{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf7b449-0bf8-44a8-8495-48569ab9b36f",
   "metadata": {},
   "source": [
    " Bags of words\n",
    "===\n",
    "\n",
    "*This notebook will show how to extract bags of words to perform dyachronic analysis of historical texts.*\n",
    "\n",
    "---\n",
    "\n",
    "## Section 1: Using word lists ...\n",
    "\n",
    "... from psychometric tools and obtain synonyms and hyponyms using WordNet"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61f544e8-c1e7-4f95-b0b7-5a8e0da5b031",
   "metadata": {},
   "source": [
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f19bde3a-5d20-4dae-bbe2-2448bfa06519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "\n",
    "# Download if necessary\n",
    "try:\n",
    "    os.path.exists(os.path.expanduser(\"~/nltk_data/\"))\n",
    "except:\n",
    "    nltk.download(\"all\")\n",
    "\n",
    "\n",
    "# prompt for input?\n",
    "check_word_lists = False\n",
    "\n",
    "# path to literary plays\n",
    "PATH_PLAYS = \"./data/plays\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502c05a-e59f-41ba-b7e7-61bcc5b938c2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">Content of PATH_PLAYS yet to clarify</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f224e-2b65-43c3-8ec5-92d28acf2f73",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a8d355f-a4dd-4471-8c6e-f77d3bf224ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_meanings(word_list):\n",
    "    \"\"\"\n",
    "    Generates a list of word meanings/definitions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    word_list : a list of words\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list with word meanings and definitions.\n",
    "\n",
    "    \"\"\"\n",
    "    word_meaning_def = []\n",
    "\n",
    "    # iterate over words in the word_base list\n",
    "    for word in word_list:\n",
    "\n",
    "        ## iterate over different meanings of the word synsets\n",
    "        for meaning in wn.synsets(word, pos=wn.NOUN + wn.VERB + wn.ADJ):\n",
    "            # print(meaning)\n",
    "            # print(meaning.definition())\n",
    "            # print('\\n')\n",
    "            word_meaning_def.append([word, meaning, meaning.definition()])\n",
    "\n",
    "    # remove duplicates\n",
    "    meanings_list = []\n",
    "    [meanings_list.append(x) for x in word_meaning_def if x not in meanings_list]\n",
    "\n",
    "    return meanings_list\n",
    "\n",
    "\n",
    "def word_check(list_pre):\n",
    "    \"\"\"\n",
    "    For manually checking each word for relevance and removing irrelevant terms.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    list_pre : a list of words\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list_post : a list of words after checks\n",
    "\n",
    "    Use\n",
    "    ------\n",
    "    For each word, press 1 if it is relevant, 0 otherwise\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    list_post = []\n",
    "\n",
    "    for item in list_pre:\n",
    "\n",
    "        print(item)\n",
    "        x = input()\n",
    "\n",
    "        if x == \"1\":\n",
    "            list_post.append(item)\n",
    "\n",
    "    return list_post\n",
    "\n",
    "\n",
    "def synonyms_hyponyms(meaning_list, languages):\n",
    "    \"\"\"\n",
    "    Generates synonyms and hyponyms from pruned word base.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    meaning_list : list of meanings\n",
    "    languages : languages for search, e.g. ['eng']\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list of words in specified languages, including synomyns and hyponyms.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    word_lists = []\n",
    "    sysnet = []\n",
    "\n",
    "    ## Create a list with just sysnet meanings\n",
    "    i = 0\n",
    "    while i < len(meaning_list):\n",
    "        x = meaning_list[i][1]\n",
    "        sysnet.append(x)\n",
    "        i += 1\n",
    "\n",
    "    for language in languages:  # loop over languages\n",
    "\n",
    "        word_list = []\n",
    "\n",
    "        for word in sysnet:  # loop over words in sysnet list\n",
    "\n",
    "            for synonym in word.lemmas(language):  # synonyms\n",
    "                if synonym.name() not in word_list:\n",
    "                    word_list.append(synonym.name())\n",
    "\n",
    "            for hyponym in word.hyponyms():  # hyponyms\n",
    "                for synonym_of_hyponym in hyponym.lemmas(language):\n",
    "                    if synonym_of_hyponym.name() not in word_list:\n",
    "                        word_list.append(synonym_of_hyponym.name())\n",
    "\n",
    "    word_lists += [\n",
    "        sorted(word_list)\n",
    "    ]  # add language-specific list to global list, sorting alphabetically\n",
    "\n",
    "    for lst in word_lists:  # combine lists for each language\n",
    "        return lst\n",
    "\n",
    "\n",
    "def bag_of_words(word_list):\n",
    "    \"\"\"\n",
    "    Extracts words and removes duplicates, creating the final bag of words.\n",
    "    \"\"\"\n",
    "\n",
    "    full_list = []\n",
    "\n",
    "    for i in word_list:\n",
    "        x = i[0]\n",
    "        full_list.append(x)\n",
    "\n",
    "    final_list = []\n",
    "    [final_list.append(x) for x in full_list if x not in final_list]\n",
    "\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaafcc8-349e-4724-a9b1-386530f4706e",
   "metadata": {},
   "source": [
    "### Seed words related to financial behaviors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51026674-e78d-4351-8ad1-5f1e10e17933",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_base_financial = [\n",
    "    \"earn\",\n",
    "    \"income\",\n",
    "    \"compensation\",\n",
    "    \"livelihood\",\n",
    "    \"pay\",\n",
    "    \"paycheck\",\n",
    "    \"salary\",\n",
    "    \"wage\",\n",
    "    \"save\",\n",
    "    \"assets\",\n",
    "    \"profit\",\n",
    "    \"accumulation\",\n",
    "    \"deposit\",\n",
    "    \"installment\",\n",
    "    \"wealth\",\n",
    "    \"spend\",\n",
    "    \"purchase\",\n",
    "    \"consume\",\n",
    "    \"payment\",\n",
    "    \"fund\",\n",
    "    \"invest\",\n",
    "    \"stockmarket\",\n",
    "    \"stock\",\n",
    "    \"bond\",\n",
    "    \"securities\",\n",
    "    \"dividends\",\n",
    "    \"shareholder\",\n",
    "    \"portfolio\" \"debt\",\n",
    "    \"liability\",\n",
    "    \"credit\",\n",
    "    \"loan\",\n",
    "    \"money\",\n",
    "    \"cash\",\n",
    "    \"currency\",\n",
    "    \"bills\",\n",
    "    \"coins\",\n",
    "    \"rich\",\n",
    "    \"poor\",\n",
    "    \"bank\",\n",
    "    \"economy\",\n",
    "    \"financial\",\n",
    "]\n",
    "\n",
    "# Create a list of meanings and definitions\n",
    "financial_list_meanings = generate_meanings(word_base_financial)\n",
    "financial_list_pruned = financial_list_meanings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f8cbe6-e699-4085-b29c-71c16b921a54",
   "metadata": {},
   "source": [
    "##### Optional: Manually remove irrelevant words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c5f241-fb3b-4ab1-b30c-42cb648d7e73",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">type 0 to exclude, 1 to include</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c438d20-dee9-44fe-bec8-f7759039910e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if check_word_lists:\n",
    "    financial_list_pruned = word_check(financial_list_pruned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0603d0-0c7c-42bf-af70-6b320e81ec29",
   "metadata": {},
   "source": [
    "##### Show list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6c020b4-78e9-4c1b-9f3b-327256b0fa45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['earn',\n",
       "  Synset('gain.v.08'),\n",
       "  'earn on some commercial or business transaction; earn as salary or wages'],\n",
       " ['earn',\n",
       "  Synset('earn.v.02'),\n",
       "  \"acquire or deserve by one's efforts or actions\"],\n",
       " ['income',\n",
       "  Synset('income.n.01'),\n",
       "  'the financial gain (earned or unearned) accruing over a given period of time']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_list_pruned[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6923aa-91f4-403f-8c0c-3d27caa720b2",
   "metadata": {},
   "source": [
    "#### Generate the list of synonyms and hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8c7b36a-a692-463f-ad02-f02930fec920",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "languages = [\"eng\"]\n",
    "financial_list_syn_hyp = synonyms_hyponyms(financial_list_pruned, languages)\n",
    "\n",
    "# Generate meanings\n",
    "financial_list_meanings = generate_meanings(financial_list_syn_hyp)\n",
    "financial_list = financial_list_meanings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ff795a-5c8b-4e7d-bb23-443537116d2f",
   "metadata": {},
   "source": [
    "##### Optional: Exclude irrelevant words\n",
    "<div class=\"alert alert-info\">type 0 to exclude, 1 to include</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a35d057-ed97-42d0-bc0c-9eb7f9dc42f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if check_word_lists:\n",
    "    financial_list = word_check(financial_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7244a59-a137-4621-8b2d-14c56c3edd86",
   "metadata": {},
   "source": [
    "##### Show list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e31721c3-7e59-482a-b430-65ce65cdf3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Asia',\n",
       "  Synset('asia.n.01'),\n",
       "  \"the largest continent with 60% of the earth's population; it is joined to Europe on the west to form Eurasia; it is the site of some of the world's earliest civilizations\"],\n",
       " ['Asia',\n",
       "  Synset('asia.n.02'),\n",
       "  'the nations of the Asian continent collectively'],\n",
       " ['Bond', Synset('chemical_bond.n.01'), 'an electrical force linking atoms']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_list[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a5253-bb89-427d-9750-34e3756518a9",
   "metadata": {},
   "source": [
    "#### Create final word list for next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4bef4e0a-7767-4f02-8946-c2bdf6bb01c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_financial_list = bag_of_words(financial_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed646223-e0f9-41f2-a9be-ac3eada2b650",
   "metadata": {},
   "source": [
    "##### Optional: Exclude irrelevant words\n",
    "<div class=\"alert alert-info\">type 0 to exclude, 1 to include</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b60abbfb-835f-4632-b517-1e03899e0c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if check_word_lists:\n",
    "    final_financial_list = word_check(final_financial_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d63f19-7c35-4587-90ae-fc773aabc249",
   "metadata": {},
   "source": [
    "##### Show list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f12ea62-53c3-4f03-92dd-fd265bcd5e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Asia', 'Bond', 'Cash']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_financial_list[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f85a7d-75df-43b6-911e-18f0107df68e",
   "metadata": {},
   "source": [
    "### Compare lists for interrater reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2634beb-2df0-4a3a-a3f6-5e2b586d1579",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">To clarify</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b32fab95-3bd3-4a2c-bcaa-e5b8cc2f9e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a204e68c-417d-4d0d-8121-59c63cbbd06f",
   "metadata": {
    "id": "ZCk2ZCbDchya"
   },
   "source": [
    "---\n",
    "## Section 2: Generate a semantic vector map with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88b857c2-e334-4cfc-a747-80f3488d5f01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AqHA_VEac02j",
    "outputId": "eccc182c-06f4-4b69-fe31-a00a59b956de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c47509b-51b6-4553-8b48-e6a20c0f1e16",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ec495b7b-5ce0-42d3-a169-c7f4bf9d222e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def literary_words_list(file_path):\n",
    "    \"\"\"\n",
    "    Function to select .txt files and store them as a list of words, to use as input to the function WordVec\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : a file path where .txt files are located (e.g. '/path/to/texts')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list of the words in the files\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Specify root folder for file search\n",
    "    os.chdir(file_path)\n",
    "    root_folder = os.getcwd()\n",
    "\n",
    "    # Create list for clean sentences\n",
    "    words_list = []\n",
    "\n",
    "    # Iterates over the path, folders and subfolders looking for txt files\n",
    "    for path, subdirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if \".txt\" in file and \"model\" not in file:\n",
    "                print(file)\n",
    "                name = os.path.join(path, file)\n",
    "                file_text = open(name, encoding=\"utf-8\").read()\n",
    "\n",
    "                # Creates a list of paragraphs - lines\n",
    "                text_list_paragraphs = file_text.split(\"\\n\")\n",
    "\n",
    "                # Clean the paragraphs further -- getting read of \\r at the end of the line\n",
    "                for paragraph in text_list_paragraphs:\n",
    "\n",
    "                    # paragraph = paragraph.replace('\\r', '')\n",
    "\n",
    "                    # Add the paragraphs to the word2vec input list\n",
    "                    words_list += [paragraph.split(\" \")]\n",
    "\n",
    "    return words_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaba6d6-5e64-4d3b-ab18-2ceca93c93c7",
   "metadata": {},
   "source": [
    "### Create list of words from .txt files of literary plays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ea7540-2c52-4951-9b37-bd836ec4c2b6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">To clarify, yet no content at PATH_PLAYS</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac217947-6f83-4517-a172-267e5540fa70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word2vec_input = literary_words_list(PATH_PLAYS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f43151b-f43f-4731-800f-ba81a476579c",
   "metadata": {},
   "source": [
    "### Build and save the vector space with Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b12f72-f973-4538-9039-903367790055",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">Whats the purpose of SentenceCorpus? Why not using word2vec_input directly?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ea48a-dec8-4d60-ab71-cc1cc3b8d578",
   "metadata": {
    "id": "dSb5F5HT6lAC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SentenceCorpus = word2vec_input\n",
    "word2vec_output = Word2Vec(SentenceCorpus, min_count=1)\n",
    "\n",
    "# save to file\n",
    "word2vec_output.save('w2v_model.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d6698-e625-43d7-8b7d-6320cd8ff792",
   "metadata": {
    "id": "cViUsz8Z6kFU"
   },
   "source": [
    "---\n",
    "## Section 3: Use the vector semantic map ...\n",
    "...to evaluate if the bags of words created in section 1 are ecologically valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b39652-fa5e-4de9-a92f-9b0250eeb879",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e82b7a0-4e52-4d37-83f5-0a775d120395",
   "metadata": {
    "id": "I3SgEEzw-YQD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_word2vec_list(word_list, model):\n",
    "    \"\"\"\n",
    "    Uses word2vec to find the 10 semantically most similar words to each seed word in word_list\n",
    "    \"\"\"\n",
    "\n",
    "    list_of_word2vec_lists = []\n",
    "    for word in word_list:\n",
    "        try:\n",
    "\n",
    "            ## here is the crucial line - we are using the model that we trained to get the most similar words within our corpus\n",
    "            list_vects = model.wv.most_similar([word], topn=10)\n",
    "\n",
    "            new_list = []\n",
    "            new_list += [word]\n",
    "            for item in list_vects:\n",
    "                word1 = item[0]\n",
    "                new_list += [word1]\n",
    "\n",
    "            # print(new_list)\n",
    "            # print('\\n')\n",
    "            list_of_word2vec_lists += [new_list]\n",
    "\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return list_of_word2vec_lists\n",
    "\n",
    "\n",
    "def choose_word2vec_list(w2v_word_list):\n",
    "    \"\"\"\n",
    "    Checks word2vec list of 10 most similar words\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    w2v_word_list : a list of words\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list of ecologically valid words\n",
    "\n",
    "    Use\n",
    "    ------\n",
    "    For the 10 lists of words, choose the number of those that have meanings coherent with the topic\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    indices = []\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for w2v_list in w2v_word_list:\n",
    "\n",
    "        print(index, w2v_list)\n",
    "        x = input()\n",
    "        if x == \"1\":\n",
    "            indices.append(index)\n",
    "        index += 1\n",
    "\n",
    "    ## chose from the word2vec outputs, the lists that seem to have clouds of meanings coherent with prosociality\n",
    "    ## in this example we can chose, for instance (among others) indexes 3,6,9,11,13 and 14\n",
    "\n",
    "    relevant_w2v_words = list(w2v_word_list[i] for i in indices)\n",
    "\n",
    "    return [item for sublist in relevant_w2v_words for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf54c8c6-7f18-464e-90c2-8d83056c2ecc",
   "metadata": {},
   "source": [
    "### Load vector space for English in the early modern period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c4b02a-c6c9-4dbf-914a-1480665145ef",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">Maybe better moving these long word lists into separate files?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b0818c3-b112-408c-90a3-e3a26957f779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = Word2Vec.load('w2v_model.txt')\n",
    "\n",
    "\n",
    "final_financial_list = [\n",
    "    \"Maundy_money\",\n",
    "    \"absorb\",\n",
    "    \"account_payable\",\n",
    "    \"accounts_receivable\",\n",
    "    \"accumulation\",\n",
    "    \"acquirer\",\n",
    "    \"affluence\",\n",
    "    \"afford\",\n",
    "    \"amortisation\",\n",
    "    \"amortization\",\n",
    "    \"amount\",\n",
    "    \"amount_of_money\",\n",
    "    \"ante_up\",\n",
    "    \"arrears\",\n",
    "    \"assets\",\n",
    "    \"bank\",\n",
    "    \"bank_bill\",\n",
    "    \"bank_building\",\n",
    "    \"bank_deposit\",\n",
    "    \"bank_line\",\n",
    "    \"bank_loan\",\n",
    "    \"bank_note\",\n",
    "    \"banker's_bill\",\n",
    "    \"banking_company\",\n",
    "    \"banking_concern\",\n",
    "    \"banknote\",\n",
    "    \"bankroll\",\n",
    "    \"bargain\",\n",
    "    \"bawbee\",\n",
    "    \"bear\",\n",
    "    \"benefit\",\n",
    "    \"big_bucks\",\n",
    "    \"big_money\",\n",
    "    \"bill\",\n",
    "    \"bond\",\n",
    "    \"bond_certificate\",\n",
    "    \"bond_issue\",\n",
    "    \"boodle\",\n",
    "    \"bread\",\n",
    "    \"bread_and_butter\",\n",
    "    \"bring_home\",\n",
    "    \"bring_in\",\n",
    "    \"budget\",\n",
    "    \"bundle\",\n",
    "    \"buy\",\n",
    "    \"buy_back\",\n",
    "    \"buy_food\",\n",
    "    \"buy_into\",\n",
    "    \"buy_out\",\n",
    "    \"buy_up\",\n",
    "    \"buyback\",\n",
    "    \"buying\",\n",
    "    \"cache\",\n",
    "    \"call_loan\",\n",
    "    \"capital\",\n",
    "    \"cash\",\n",
    "    \"cash_flow\",\n",
    "    \"cash_in\",\n",
    "    \"cash_in_hand\",\n",
    "    \"change\",\n",
    "    \"charge\",\n",
    "    \"cheap_money\",\n",
    "    \"chickenfeed\",\n",
    "    \"chump_change\",\n",
    "    \"cleanup\",\n",
    "    \"clear\",\n",
    "    \"coin\",\n",
    "    \"coinage\",\n",
    "    \"cold_cash\",\n",
    "    \"comforts\",\n",
    "    \"commercial_bank\",\n",
    "    \"commercial_credit\",\n",
    "    \"commit\",\n",
    "    \"consume\",\n",
    "    \"consumer_loan\",\n",
    "    \"credit\",\n",
    "    \"credit_line\",\n",
    "    \"credit_union\",\n",
    "    \"crown\",\n",
    "    \"currency\",\n",
    "    \"current_assets\",\n",
    "    \"debenture\",\n",
    "    \"debt\",\n",
    "    \"deep_pocket\",\n",
    "    \"deferred_payment\",\n",
    "    \"defray\",\n",
    "    \"defrayal\",\n",
    "    \"defrayment\",\n",
    "    \"demand_deposit\",\n",
    "    \"demand_loan\",\n",
    "    \"denier\",\n",
    "    \"deplete\",\n",
    "    \"deposit\",\n",
    "    \"direct_loan\",\n",
    "    \"disbursal\",\n",
    "    \"disburse\",\n",
    "    \"disbursement\",\n",
    "    \"disposable_income\",\n",
    "    \"dissipate\",\n",
    "    \"dividend\",\n",
    "    \"divvy\",\n",
    "    \"dough\",\n",
    "    \"down_payment\",\n",
    "    \"ducat\",\n",
    "    \"earn\",\n",
    "    \"earning_per_share\",\n",
    "    \"earnings\",\n",
    "    \"easy_money\",\n",
    "    \"economic_system\",\n",
    "    \"economise\",\n",
    "    \"economize\",\n",
    "    \"economy\",\n",
    "    \"economy_of_scale\",\n",
    "    \"eightpence\",\n",
    "    \"eke_out\",\n",
    "    \"equity\",\n",
    "    \"exhaust\",\n",
    "    \"expend\",\n",
    "    \"farthing\",\n",
    "    \"final_payment\",\n",
    "    \"finance\",\n",
    "    \"finances\",\n",
    "    \"financial\",\n",
    "    \"financial_obligation\",\n",
    "    \"fiscal\",\n",
    "    \"fivepence\",\n",
    "    \"folding_money\",\n",
    "    \"fool_away\",\n",
    "    \"foot\",\n",
    "    \"fourpence\",\n",
    "    \"free_enterprise\",\n",
    "    \"fritter\",\n",
    "    \"fritter_away\",\n",
    "    \"frivol_away\",\n",
    "    \"fund\",\n",
    "    \"funds\",\n",
    "    \"gain\",\n",
    "    \"gelt\",\n",
    "    \"give_back\",\n",
    "    \"government_income\",\n",
    "    \"government_note\",\n",
    "    \"government_revenue\",\n",
    "    \"government_security\",\n",
    "    \"gravy_train\",\n",
    "    \"greenback\",\n",
    "    \"groat\",\n",
    "    \"gross\",\n",
    "    \"gross_profit\",\n",
    "    \"gross_profit_margin\",\n",
    "    \"gross_revenue\",\n",
    "    \"gross_sales\",\n",
    "    \"growth_stock\",\n",
    "    \"guinea\",\n",
    "    \"ha'penny\",\n",
    "    \"half-pay\",\n",
    "    \"half_crown\",\n",
    "    \"halfpenny\",\n",
    "    \"hard_cash\",\n",
    "    \"hard_currency\",\n",
    "    \"hedge_fund\",\n",
    "    \"hedgefund\",\n",
    "    \"hive_up\",\n",
    "    \"hoard\",\n",
    "    \"hole_card\",\n",
    "    \"home_equity_credit\",\n",
    "    \"home_equity_loan\",\n",
    "    \"home_loan\",\n",
    "    \"homeless\",\n",
    "    \"immediate_payment\",\n",
    "    \"impulse-buy\",\n",
    "    \"income\",\n",
    "    \"indebtedness\",\n",
    "    \"industrialism\",\n",
    "    \"inherited_wealth\",\n",
    "    \"installment\",\n",
    "    \"installment_credit\",\n",
    "    \"installment_loan\",\n",
    "    \"invest\",\n",
    "    \"investment\",\n",
    "    \"investment_funds\",\n",
    "    \"invoice\",\n",
    "    \"job\",\n",
    "    \"keep\",\n",
    "    \"laissez-faire_economy\",\n",
    "    \"lavish\",\n",
    "    \"lay_aside\",\n",
    "    \"lay_away\",\n",
    "    \"lay_out\",\n",
    "    \"letter_of_credit\",\n",
    "    \"letter_security\",\n",
    "    \"liability\",\n",
    "    \"limited_liability\",\n",
    "    \"line_of_credit\",\n",
    "    \"line_one's_pockets\",\n",
    "    \"liquid_assets\",\n",
    "    \"liquidate\",\n",
    "    \"listed_security\",\n",
    "    \"livelihood\",\n",
    "    \"living\",\n",
    "    \"living_wage\",\n",
    "    \"loan\",\n",
    "    \"lucre\",\n",
    "    \"lump_sum\",\n",
    "    \"luxuriate\",\n",
    "    \"luxuriousness\",\n",
    "    \"luxury\",\n",
    "    \"maintenance\",\n",
    "    \"make\",\n",
    "    \"margin\",\n",
    "    \"market_economy\",\n",
    "    \"markup\",\n",
    "    \"material_resource\",\n",
    "    \"meal_ticket\",\n",
    "    \"megabucks\",\n",
    "    \"member_bank\",\n",
    "    \"merchant_bank\",\n",
    "    \"metal_money\",\n",
    "    \"minimum_wage\",\n",
    "    \"mintage\",\n",
    "    \"misspend\",\n",
    "    \"mixed_economy\",\n",
    "    \"monetary_fund\",\n",
    "    \"monetary_resource\",\n",
    "    \"money\",\n",
    "    \"moolah\",\n",
    "    \"mortgage_loan\",\n",
    "    \"mutual_fund\",\n",
    "    \"needy\",\n",
    "    \"nest_egg\",\n",
    "    \"net_income\",\n",
    "    \"net_profit\",\n",
    "    \"net_sales\",\n",
    "    \"nickel-and-dime\",\n",
    "    \"ninepence\",\n",
    "    \"non-market_economy\",\n",
    "    \"note\",\n",
    "    \"opulence\",\n",
    "    \"ordinary_shares\",\n",
    "    \"outlay\",\n",
    "    \"overage\",\n",
    "    \"overpay\",\n",
    "    \"overpayment\",\n",
    "    \"overspend\",\n",
    "    \"paper_currency\",\n",
    "    \"paper_money\",\n",
    "    \"pay\",\n",
    "    \"pay_cash\",\n",
    "    \"pay_envelope\",\n",
    "    \"pay_off\",\n",
    "    \"pay_out\",\n",
    "    \"pay_packet\",\n",
    "    \"pay_up\",\n",
    "    \"payable\",\n",
    "    \"paycheck\",\n",
    "    \"payment\",\n",
    "    \"payoff\",\n",
    "    \"payroll_check\",\n",
    "    \"pecuniary_resource\",\n",
    "    \"pelf\",\n",
    "    \"penny\",\n",
    "    \"penny-pinch\",\n",
    "    \"pension_fund\",\n",
    "    \"per_capita_income\",\n",
    "    \"personal_credit_line\",\n",
    "    \"personal_income\",\n",
    "    \"personal_line_of_credit\",\n",
    "    \"personal_loan\",\n",
    "    \"petty_cash\",\n",
    "    \"pick_up\",\n",
    "    \"pile\",\n",
    "    \"pin_money\",\n",
    "    \"pittance\",\n",
    "    \"pocket_money\",\n",
    "    \"poor\",\n",
    "    \"poor_people\",\n",
    "    \"premium\",\n",
    "    \"prepay\",\n",
    "    \"prepayment\",\n",
    "    \"proceeds\",\n",
    "    \"profit\",\n",
    "    \"profits\",\n",
    "    \"protection\",\n",
    "    \"pull_in\",\n",
    "    \"purchase\",\n",
    "    \"purchasing\",\n",
    "    \"quick_assets\",\n",
    "    \"quick_buck\",\n",
    "    \"quittance\",\n",
    "    \"rake_in\",\n",
    "    \"ready_cash\",\n",
    "    \"ready_money\",\n",
    "    \"realise\",\n",
    "    \"realize\",\n",
    "    \"receivables\",\n",
    "    \"recompense\",\n",
    "    \"redeem\",\n",
    "    \"redeposit\",\n",
    "    \"refund\",\n",
    "    \"regular_payment\",\n",
    "    \"remission\",\n",
    "    \"remit\",\n",
    "    \"remitment\",\n",
    "    \"remittal\",\n",
    "    \"remittance\",\n",
    "    \"remunerate\",\n",
    "    \"remuneration\",\n",
    "    \"rental_income\",\n",
    "    \"repay\",\n",
    "    \"repayment\",\n",
    "    \"repurchase\",\n",
    "    \"reserve\",\n",
    "    \"reserve_assets\",\n",
    "    \"reserve_bank\",\n",
    "    \"resource\",\n",
    "    \"retrenchment\",\n",
    "    \"return\",\n",
    "    \"reward\",\n",
    "    \"rich\",\n",
    "    \"rich_people\",\n",
    "    \"richness\",\n",
    "    \"salary\",\n",
    "    \"sales\",\n",
    "    \"save\",\n",
    "    \"save_up\",\n",
    "    \"saving\",\n",
    "    \"savings\",\n",
    "    \"scrimp\",\n",
    "    \"secured_bond\",\n",
    "    \"security\",\n",
    "    \"security_deposit\",\n",
    "    \"shareholder\",\n",
    "    \"shareowner\",\n",
    "    \"shekels\",\n",
    "    \"shilling\",\n",
    "    \"shinplaster\",\n",
    "    \"shoot\",\n",
    "    \"shower\",\n",
    "    \"sick_pay\",\n",
    "    \"sixpence\",\n",
    "    \"skimp\",\n",
    "    \"small_change\",\n",
    "    \"specie\",\n",
    "    \"spend\",\n",
    "    \"spending\",\n",
    "    \"spending_money\",\n",
    "    \"splurge\",\n",
    "    \"squander\",\n",
    "    \"stash\",\n",
    "    \"state_bank\",\n",
    "    \"sterling\",\n",
    "    \"stint\",\n",
    "    \"stock\",\n",
    "    \"stock_certificate\",\n",
    "    \"stock_dividend\",\n",
    "    \"stockholder\",\n",
    "    \"stockpile\",\n",
    "    \"subscribe\",\n",
    "    \"subscribe_to\",\n",
    "    \"subscription\",\n",
    "    \"subsidisation\",\n",
    "    \"subsidization\",\n",
    "    \"subsistence\",\n",
    "    \"sufficiency\",\n",
    "    \"sum\",\n",
    "    \"sum_of_money\",\n",
    "    \"sumptuousness\",\n",
    "    \"support\",\n",
    "    \"support_payment\",\n",
    "    \"surcharge\",\n",
    "    \"sustenance\",\n",
    "    \"take-home_pay\",\n",
    "    \"take_home\",\n",
    "    \"take_in\",\n",
    "    \"takings\",\n",
    "    \"tenpence\",\n",
    "    \"threepence\",\n",
    "    \"thriftiness\",\n",
    "    \"tighten_one's_belt\",\n",
    "    \"time_loan\",\n",
    "    \"token_money\",\n",
    "    \"token_payment\",\n",
    "    \"treasury_stock\",\n",
    "    \"trifle\",\n",
    "    \"trifle_away\",\n",
    "    \"trust_fund\",\n",
    "    \"tuppence\",\n",
    "    \"turn_a_nice_penny\",\n",
    "    \"turn_a_profit\",\n",
    "    \"twopence\",\n",
    "    \"undercharge\",\n",
    "    \"underpay\",\n",
    "    \"underpayment\",\n",
    "    \"underspend\",\n",
    "    \"unearned_income\",\n",
    "    \"unearned_revenue\",\n",
    "    \"use_up\",\n",
    "    \"wage\",\n",
    "    \"wampum\",\n",
    "    \"wanton\",\n",
    "    \"wanton_away\",\n",
    "    \"ware\",\n",
    "    \"waste\",\n",
    "    \"wealth\",\n",
    "    \"wealthiness\",\n",
    "    \"working_capital\",\n",
    "    \"yield\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac0d8f2-66c8-45a4-b7a6-43d7e4e94681",
   "metadata": {},
   "source": [
    "#### Create lists of ecologically valid words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "258e8b7b-0a5d-4864-a0ac-cc160c8e02a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_financial_w2v = get_word2vec_list(final_Financial_list, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c17b314-1b11-45bc-874b-c2cebd906786",
   "metadata": {},
   "source": [
    "#### Choose most relevant lists of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56387ef9-39e6-43fe-a383-6cc87f9cd084",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">type 0 to exclude, 1 to include</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d8fa3e8-fd0e-4ac5-b30b-4b8ebc9928ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_BoW = choose_word2vec_list(list_of_financial_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf47db31-206a-4aa5-8550-791dc055347f",
   "metadata": {},
   "source": [
    "##### Show list with duplicates removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a9594f-d82d-42e3-9451-326e4ce233d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(set(financial_BoW)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0377fe94-9617-43b3-9f5c-4093de706fc6",
   "metadata": {},
   "source": [
    "### Check words again using word_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddde8537-f061-4b7a-b004-7d33ecd8a49c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">type 0 to exclude, 1 to include</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b13df9-f287-40fe-854f-51979f16b6ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Financial_BoW = word_check(financial_BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b56a2a-d06f-41e6-9f81-d04612870396",
   "metadata": {},
   "source": [
    "### Final list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391ecd3c-3bc3-4707-a5bd-1b8005ec0091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "FINANCIAL_BoW = list(set(Financial_BoW))\n",
    "\n",
    "## Final bags of words for frequency analyses\n",
    "print('financial terms\\n\\n', FINANCIAL_BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f739df-4f59-4015-bbb7-b512e1b3c0a3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">See next script.</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
