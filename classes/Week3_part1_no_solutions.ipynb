{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 3 Part I\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIddMbzAvaeD"
   },
   "source": [
    "In this class we will finish covering functions, and also talk about dictionaries and modules. In particular, we will look at how to use the natural language processing module (nltk) to:\n",
    " -  do simple sentiment analysis\n",
    " - calculate word frequencies\n",
    " - use dictionary tools. \n",
    "\n",
    "After these examples, we will learn how to clear the text using pre-processing functions, and finally add it all together\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bu539SPPxLdW"
   },
   "source": [
    "1.6. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0GL1cwcxYsy"
   },
   "source": [
    "*1.6. exercise*\n",
    "\n",
    "Create a function that calculates the **frequency** of the vowel 'a' in the list of sentences\n",
    "\n",
    "list_of_sentences = ['I am ultrasonic', 'Peter likes to pantomime','I only play the ukulele in the beach','but I love beer anytime','my preferences are orthogonal to my skill']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V0zlPLrDwbhH"
   },
   "outputs": [],
   "source": [
    "## define list of sentences\n",
    "\n",
    "list_of_sentences = ['I am ultrasonic', 'Peter likes to pantomime','I only play the ukulele in the beach','but I love beer anytime','my preferences are orthogonal to my skill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwPZDMOsxo2V"
   },
   "outputs": [],
   "source": [
    "## creating function1\n",
    "\n",
    "def sentence_to_letterList(sentence):\n",
    "\n",
    "  ##empty list\n",
    "  list_wien = []\n",
    "\n",
    "  ##loop\n",
    "  for item in sentence:\n",
    "    ## add item to the list_wien\n",
    "    list_wien += [item]\n",
    "\n",
    "  ## output the list\n",
    "  return(list_wien)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgV1e8SrwKdi"
   },
   "outputs": [],
   "source": [
    "## creating function2\n",
    "\n",
    "def vowel_frequency(sentence):\n",
    "\n",
    "  ##use function1 created above to generate a list of letters \n",
    "  word_list = sentence_to_letterList(sentence)\n",
    "\n",
    "  ##get length of that list\n",
    "  length = len(word_list)\n",
    "\n",
    "  ## count isntances of 'a'\n",
    "  counts = sentence.count('a')\n",
    "\n",
    "  ## compute the frequency\n",
    "  frequency = counts/length\n",
    "  \n",
    "  ## output both the counts and the frequency\n",
    "  return(counts, frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1LWbuH_R_03"
   },
   "outputs": [],
   "source": [
    "## execute the function\n",
    "list_of_sentences = ['I am ultrasonic', 'Peter likes to pantomime','I only play the ukulele in the beach','but I love beer anytime','my preferences are orthogonal to my skill']\n",
    "\n",
    "for sentence in list_of_sentences:\n",
    "\n",
    "  ## create a variable vowel frequency-vf to store the output of function2 -counts and frequency\n",
    "  vf = vowel_frequency(sentence)\n",
    "\n",
    "  ## print the sentence and the output of the function vowel_frequency\n",
    "  print(sentence, '; frequency of a is:', vf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEFpayXeylK1"
   },
   "source": [
    "*1.6. exercise*\n",
    "\n",
    "Create a function that calculates the **frequency** of the vowels ['a','e','i','o','u'] in the list of sentences\n",
    "\n",
    "list_of_sentences = ['I am ultrasonic', 'Peter likes to pantomime','I only play the ukulele in the beach','but I love beer anytime','my preferences are orthogonal to my skill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EiqvlgMykZw"
   },
   "outputs": [],
   "source": [
    "## define list of sentences\n",
    "list_of_sentences = ['I am ultrasonic', 'Peter likes to pantomime','I only play the ukulele in the beach','but I love beer anytime','my preferences are orthogonal to my skill']\n",
    "\n",
    "## define list of vowels\n",
    "vowels = ['a','e','i','o','u']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5lTnBdcIy7CJ"
   },
   "outputs": [],
   "source": [
    "## define function3\n",
    "\n",
    "def vowel_frequency(sentence, vowels):\n",
    "\n",
    "  ## input is a sentence and a list of vowels\n",
    "  ## output is the frequency of all vowels\n",
    "\n",
    "  word_list = sentence_to_letterList(sentence)\n",
    "  length = len(sentence)\n",
    "\n",
    "  ## create list to store the vowel frequencies\n",
    "  vowel_freqs = []\n",
    "\n",
    "  ## iterate over list of vowels\n",
    "  for vowel in vowels:\n",
    "    counts = sentence.count(vowel)\n",
    "    frequency =counts/length\n",
    "    vowel_freqs += [frequency]\n",
    "  return(vowel_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QtFGOPgw0yK6"
   },
   "outputs": [],
   "source": [
    "## run function3 for each sentence\n",
    "\n",
    "for sentence in list_of_sentences:\n",
    "  vf = vowel_frequency(sentence, vowels)\n",
    "  print(sentence, '; frequencies of a e i o u, are:', vf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bntx1FK10xbM"
   },
   "source": [
    "# 1.7 Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNtUnFdn1ekZ"
   },
   "outputs": [],
   "source": [
    "dictionary_vowels = {'a': 0.2, 'e': 0.3, 'i': 0.0, 'o': 0.8, 'u': 0.5 }\n",
    "\n",
    "dictionary_vowels['u']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wuwgoaK81kfi"
   },
   "outputs": [],
   "source": [
    "dictionary_vowels = {}\n",
    "dictionary_vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKIXzaHy1oB-"
   },
   "outputs": [],
   "source": [
    "dictionary_vowels['a']=0.2\n",
    "dictionary_vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RqWehCX41tUn"
   },
   "outputs": [],
   "source": [
    "dictionary_vowels['e']=0.3\n",
    "dictionary_vowels['i']=0.0\n",
    "dictionary_vowels['o']=0.8\n",
    "dictionary_vowels['u']=0.5\n",
    "\n",
    "dictionary_vowels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKllta5M1sXa"
   },
   "source": [
    "1.7. exercise\n",
    "Get frequencies of vowels per sentence, but use dictionary instead of list, \n",
    "####e.g. {'a': 0.2, 'e': 0.3, 'i': 0.0, 'o': 0.8, 'u': 0.5 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXlh2f3c15YW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11luXfsz18fZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4vCRVJZg2ByL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbrugRiICVFO"
   },
   "source": [
    "##1.7.5 LAMBDA functions\n",
    "\n",
    "####**Python Lambda Functions** are anonymous function means that the function is without a name. As we already know that the def keyword is used to define a normal function in Python. Similarly, the lambda keyword is used to define an anonymous function in Python. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7v881YsYCrKY"
   },
   "outputs": [],
   "source": [
    "numbers = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjZ9MhacKYek"
   },
   "outputs": [],
   "source": [
    "# function to calculate the square of a number\n",
    "\n",
    "def square (input1):\n",
    "  return(input1 * input1)\n",
    "\n",
    "## compute the square for each number in the list\n",
    "for num in numbers:\n",
    "  print(square(num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koirGyDEMkb4"
   },
   "source": [
    "\n",
    "#####Python Lambda Function Syntax:\n",
    "#####lambda arguments: expression\n",
    "\n",
    "*This function can have any number of arguments but only one expression, which is evaluated and returned.\n",
    "One is free to use lambda functions wherever function objects are required.\n",
    "You need to keep in your knowledge that lambda functions are syntactically restricted to a single expression.\n",
    "It has various uses in particular fields of programming, besides other types of expressions in functions.*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LrzeuIvfFP6h"
   },
   "outputs": [],
   "source": [
    "## The LAMBDA way to write a function\n",
    "## it takes input var1 (on the left ot :), and generates var1*var1 (on the right of :)\n",
    "\n",
    "funct = lambda var1 : var1* var1\n",
    "\n",
    "for num in numbers:\n",
    "  print(funct(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rk4sIXDeLpMR"
   },
   "outputs": [],
   "source": [
    "## the advantage is that we can use the function is situ\n",
    "\n",
    "for num in numbers:\n",
    "  square = lambda var1 : var1* var1\n",
    "  print(square(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMQ_XNRAMjP3"
   },
   "outputs": [],
   "source": [
    "## for example function that takes \n",
    "\n",
    "numbers = [1,2,3,4,5]\n",
    "\n",
    "result = 1\n",
    "\n",
    "for num in numbers:\n",
    "\n",
    "  ## lambda function takes 2 variables: var1 and var2 and sums them\n",
    "  square = lambda var1,var2 : var1+var2\n",
    "\n",
    "  ## takes each element of the list numbers\n",
    "  ## sums the list element with the result of the previous sum\n",
    "  result = square(num,result)\n",
    "  \n",
    "  print(\"num \",num,'+','previous result',result-num,\"is: \",result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEoiRgovjupu"
   },
   "source": [
    "1.8. Using conditional expressions to filter lists, and simple ways to write conditional loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReWB_I2WC-9T"
   },
   "outputs": [],
   "source": [
    "## how to write simple loops with conditional expressions\n",
    "\n",
    "numbers = [1,2,3,4,5]\n",
    "\n",
    "for num in numbers:\n",
    "\n",
    "  ## if expression filters the output\n",
    "  if num > 2:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6T1ShEE0mOoR"
   },
   "outputs": [],
   "source": [
    "## how to write simple loops with conditional expressions\n",
    "\n",
    "numbers = [1,2,3,4,5]\n",
    "\n",
    "for num in numbers:\n",
    "\n",
    "  ## if expression filters the output\n",
    "  if num > 2 and num < 5:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pM6em5sNOxIi"
   },
   "outputs": [],
   "source": [
    "## create a filtered list\n",
    "\n",
    "##original list\n",
    "numbers = [1,2,3,4,5]\n",
    "\n",
    "## empty list to add information later\n",
    "filtered_list = []\n",
    "\n",
    "##iterate overlist of numbers\n",
    "for num in numbers:\n",
    "  ## filter out numbers smaller than 3 and bigger than 5\n",
    "  if num > 2 and num < 5:\n",
    "\n",
    "    ## if num is not filtered out, add it to the new list\n",
    "    filtered_list += [num]\n",
    "\n",
    "print(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97mkIipSOBY-"
   },
   "outputs": [],
   "source": [
    "## filter in one line\n",
    "\n",
    "filtered_list = [num for num in numbers if num > 2 and num <5]\n",
    "\n",
    "print(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OItgnDQNPiZV"
   },
   "outputs": [],
   "source": [
    "##  combine with lambda functions\n",
    "numbers = [1,2,3,4,5]\n",
    "\n",
    "## function to calculate square\n",
    "funct = lambda var1 : var1* var1\n",
    "\n",
    "## we apply the fucntion lambda before adding it to the filtered list\n",
    "filtered_list = [funct(num) for num in numbers if num > 2 and num <5]\n",
    "\n",
    "print(filtered_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZzsWrxE1ip3"
   },
   "source": [
    "## 1.9 Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3zK2Kkc5Jiv"
   },
   "source": [
    "# 1.9.1 NLTK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "erdltmwE2-Qk"
   },
   "outputs": [],
   "source": [
    "## install and import all natural language tool kit (nltk) functions\n",
    "\n",
    "!pip install nltk \n",
    "import nltk\n",
    "nltk.download('all') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFkGkQaZ3OId"
   },
   "outputs": [],
   "source": [
    "## function to create a list of sentences: sent_tokenize()\n",
    "\n",
    "text=\"Hello Mr. Smith, how are you doing today? The weather is great, and city is awesome. The sky is pinkish-blue. You shouldn't eat cardboard\"\n",
    "\n",
    "tokenized_text=nltk.sent_tokenize(text)\n",
    "\n",
    "print(tokenized_text)\n",
    "\n",
    "for sentence in tokenized_text:\n",
    "  print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0URnkYo03g96"
   },
   "outputs": [],
   "source": [
    "## function to create a list of words: word_tokenize()\n",
    "\n",
    "tokenized_word= nltk.word_tokenize(text)\n",
    "\n",
    "print(tokenized_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIpwCcWF3tbR"
   },
   "outputs": [],
   "source": [
    "## function to calculate frequency distribution FreqDist\n",
    "\n",
    "fdist = nltk.FreqDist(tokenized_word)\n",
    "\n",
    "## the object FreqDist has tupples with the word and its counts\n",
    "fdist.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COKLBBJT4PLo"
   },
   "outputs": [],
   "source": [
    "## Parts of Speech - grammatical categorization of a words in a sentence, input is a sentence\n",
    "## the function is pos_tag()\n",
    "\n",
    "sentence = 'this is a sentence'\n",
    "tokenized_word= nltk.word_tokenize(sentence)\n",
    "\n",
    "nltk.pos_tag(tokenized_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uIH71zsGBdjV"
   },
   "outputs": [],
   "source": [
    "## Now it is time to lemmatize the tokens of out list\n",
    "## Lemmatizing is to transform related words into their root, so that they are counted as several instances of the same word.\n",
    "## for example run, running , ran are all different words but they should be counted as 3 instances of the verb 'run'\n",
    "## in order to avoid that python takes them as the different words, we need to lemmatize our list of tokens\n",
    "\n",
    "## first we import the lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "## we need to store the lemmatizer into a variable\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "w1 = 'ascended'\n",
    "\n",
    "lemma.lemmatize(word=w1, pos='v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnuCdhZH5gHJ"
   },
   "source": [
    "1.9.2. Simple Plots - Matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Fa0G7bO4SaM"
   },
   "outputs": [],
   "source": [
    "# Frequency Distribution Plot\n",
    "## the module is called matplotlit and we can import it with the name plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## we can plot our frequency distribution\n",
    "fdist.plot(10,cumulative=False)\n",
    "\n",
    "## to display a plot we need to type plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTupx8dp7Xod"
   },
   "source": [
    "1.9.3. Simple Sentiment Analysis - Vader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EkN1CLcO4g7X"
   },
   "outputs": [],
   "source": [
    "## modules for sentiment analysis\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "## the analyzer needs to be stored in a variable\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "## we can calculate polarity scores, these are a dictionary\n",
    "sid.polarity_scores(\"this sentence is the absolute best!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQUOS33PsB2l"
   },
   "outputs": [],
   "source": [
    "## we can calculate polarity scores, these are a dictionary\n",
    "sid.polarity_scores(\"this sentence is the absolute best!!!\")['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9G2hFd27y59"
   },
   "source": [
    "1.9.4. Contractions and Inflections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pA0FK_ZX7v4q"
   },
   "outputs": [],
   "source": [
    "!pip install contractions\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4QxvG9U4-st"
   },
   "outputs": [],
   "source": [
    "## fix contractions in english\n",
    "\n",
    "contractions.fix(\"You shouldn't eat cardboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z9iQNF1Q5GB9"
   },
   "outputs": [],
   "source": [
    "## This function turns numeric values into words, \"6\" into \"six\"\n",
    "## we need to use the module inflect for this\n",
    "\n",
    "import inflect\n",
    "\n",
    "## we create a variable for the engine of the module inflect\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLojD8nv8qdt"
   },
   "outputs": [],
   "source": [
    "p.number_to_words(4237)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKpRpMmC825D"
   },
   "source": [
    "## 1.10. VERY IMPORTANT MODULE - RE - Regular Expression Operations\n",
    "\n",
    "####https://docs.python.org/3/howto/regex.html\n",
    "https://www.oreilly.com/content/an-introduction-to-regular-expressions/#:~:text=A%20regular%20expression%20matches%20a,%2C%20substring%2C%20or%20split%20text.\n",
    "\n",
    "https://www3.ntu.edu.sg/home/ehchua/programming/howto/Regexe.html\n",
    "\n",
    "Regular expressions (called REs, or regexes, or regex patterns) are essentially a tiny, highly specialized programming language embedded inside Python and made available through the re module. Using this little language, you specify the rules for the set of possible strings that you want to match; this set might contain English sentences, or e-mail addresses, or TeX commands, or anything you like. You can then ask questions such as “Does this string match the pattern?”, or “Is there a match for the pattern anywhere in this string?”. You can also use REs to modify a string or to split it apart in various ways.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_UzbhpJP8-2h"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AA1ew5y-xAF"
   },
   "outputs": [],
   "source": [
    "## findall() returns characters that fit the conditions\n",
    "## '.' means any kind of character, i.e. there is no filter\n",
    "re.findall('.','I love beef 100%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFH_nWLLV1PD"
   },
   "outputs": [],
   "source": [
    "## '..' means any bigram\n",
    "re.findall('..','I love beef 100%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqPG4wnfWEG2"
   },
   "outputs": [],
   "source": [
    "##returns a list of all trigrams\n",
    "re.findall('...','I love beef 100%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYkTI8ems7Wk"
   },
   "outputs": [],
   "source": [
    "## 'ee' means trigrams with e in the middle\n",
    "re.findall('.e.','I love beef 100%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_7sbktLVc44"
   },
   "outputs": [],
   "source": [
    "## with [] inside the '' we can filter in particular objects, for example, only letters between a and e\n",
    "re.findall('[a-e]','I love soja 100%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_Ns49BwWp7f"
   },
   "outputs": [],
   "source": [
    "## or we can filter them out with ^\n",
    "re.findall('[^a-e]','I love soja 100%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3Tqz7fdVdFC"
   },
   "outputs": [],
   "source": [
    "##only lower case alphabetic\n",
    "re.findall('[a-z]','I love beef 100%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpj2TGCWW1h8"
   },
   "outputs": [],
   "source": [
    "##both lower case and upper case alphabetic\n",
    "re.findall('[a-zA-Z]','I love beef 100%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9tyBVMvXAhr"
   },
   "outputs": [],
   "source": [
    "##all alphanumeric including spaces\n",
    "re.findall('[a-zA-Z0-9 ]','I love beef 100%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DO1g8HVsXgXC"
   },
   "outputs": [],
   "source": [
    "## an important function from re is sub - which can filter out directly in the text characters that we dont want\n",
    "\n",
    "sentence = \"This sentence is A mess b-e-c-a-u-s-e I just looove <3 <3 to write gibberish !!! ***, just check me out at http://www.mauricioIZdaBest.awesome\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "etKvncSZX_T_"
   },
   "outputs": [],
   "source": [
    "## substitute non-alphabetic with empty\n",
    "filtered_sentence= re.sub(r'[^a-zA-Z ]', '', sentence)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kt3OsmdQA3xt"
   },
   "outputs": [],
   "source": [
    "## filter out expressions starting with http\\ until they it finds a non-white space\n",
    "## \\S means non-white space\n",
    "\n",
    "filtered_sentence = re.sub(r'http\\S+', '', sentence)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPm-eyJYZc_I"
   },
   "source": [
    "##Exercise: generate and print the lower cased sentence below with only alphabetic characters, without websites and without double spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1z_mZkVA6Ag"
   },
   "outputs": [],
   "source": [
    "## sequential filtering\n",
    "\n",
    "sentence = \"This sentence is A mess b-e-c-a-u-s-e I just    looove    <3 <3 to write gibberish !!! ***, just check me out at http://www.mauricioIZdaBest.awesome\"\n",
    "\n",
    "s1 = sentence.lower()\n",
    "s2 = re.sub('http\\S+', '', s1)\n",
    "s3 = re.sub('[^a-z ]', '', s2)\n",
    "\n",
    "## the expression \\s+ finds all white spaces bigger than 1\n",
    "s4 = re.sub(' \\s+', ' ', s3)\n",
    "print (s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkcwA5VOcKpz"
   },
   "source": [
    "Exercise: \n",
    "\n",
    "using Vader, calculate the sentiment scores of each sentence of the following text\n",
    "\n",
    "sentence = \"My LIFE just changed for the better thousand times over... You won't believe how much this APP is A-M-A-Z-I-N_G. This ain't no joke.  I love it *****. You will love it too. The only bad thing is that it is EXPENSIVE. AND my mom doesn't like it.\"\n",
    "\n",
    "IMPORTANT:\n",
    "\n",
    "- resolve inflections (import and use the right modules).\n",
    "- generate a list of the lowercased sentences, with alphabetic characters and single spaces.\n",
    "\n",
    "NOTE: you need . to separate sentences, so don't remove .'s before separating the sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m93HGslLhGk1"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCIti2nrcJ4-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fdmolPhgeAb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38NNTTe5gbSo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h60yKLtxijvh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
