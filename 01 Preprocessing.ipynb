{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing\n",
    "===\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import inflect\n",
    "from nltk import ConcordanceIndex\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# import nltk # TODO really needed?\n",
    "\n",
    "\n",
    "TEXT_PATH = \"./data/text\"\n",
    "\n",
    "\n",
    "# lemma = WordNetLemmatizer() # TODO really needed?\n",
    "# p = inflect.engine() # TODO really needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text analysis is more accurate when we remove the most common words from the list of tokens. \n",
    "Hypercommon words are called stop words, and there is a list of stopwords for every language. Here we import the stopwords from nltk module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect texts from files and create a list for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CareyGeorge Saville-1770-Analects in verse an2...</td>\n",
       "      <td>CareyGeorge Saville</td>\n",
       "      <td>1770</td>\n",
       "      <td>Analects in verse an22.txt</td>\n",
       "      <td>\\n\\nA Room in Brainly's House.\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CentlivreSusanna-1707-The platonick lady 26.txt</td>\n",
       "      <td>CentlivreSusanna</td>\n",
       "      <td>1707</td>\n",
       "      <td>The platonick lady 26.txt</td>\n",
       "      <td>\\n\\n\\n\\nAS I was saying, Sir, I have advanc'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KingThomas-1769-Wit's last stake A 19.txt</td>\n",
       "      <td>KingThomas</td>\n",
       "      <td>1769</td>\n",
       "      <td>Wit's last stake A 19.txt</td>\n",
       "      <td>MARTIN and LUCETTA meeting.\\n\\n\\n\\nMR. Martin,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PhilipsWilliam-1700-St StephensGreen 213.txt</td>\n",
       "      <td>PhilipsWilliam</td>\n",
       "      <td>1700</td>\n",
       "      <td>St StephensGreen 213.txt</td>\n",
       "      <td>\\n\\n\\n\\n\\nWELL, well, Aemilia, You may pre∣ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Middleton Thomas-1606-The Revenger's Tragedy.txt</td>\n",
       "      <td>Middleton Thomas</td>\n",
       "      <td>1606</td>\n",
       "      <td>The Revenger's Tragedy.txt</td>\n",
       "      <td>duke royal lecher go grey haired adultery \\nan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file               author  \\\n",
       "0  CareyGeorge Saville-1770-Analects in verse an2...  CareyGeorge Saville   \n",
       "1    CentlivreSusanna-1707-The platonick lady 26.txt     CentlivreSusanna   \n",
       "2          KingThomas-1769-Wit's last stake A 19.txt           KingThomas   \n",
       "3       PhilipsWilliam-1700-St StephensGreen 213.txt       PhilipsWilliam   \n",
       "4   Middleton Thomas-1606-The Revenger's Tragedy.txt     Middleton Thomas   \n",
       "\n",
       "   year                       title  \\\n",
       "0  1770  Analects in verse an22.txt   \n",
       "1  1707   The platonick lady 26.txt   \n",
       "2  1769   Wit's last stake A 19.txt   \n",
       "3  1700    St StephensGreen 213.txt   \n",
       "4  1606  The Revenger's Tragedy.txt   \n",
       "\n",
       "                                                text  \n",
       "0  \\n\\nA Room in Brainly's House.\\n\\n\\n\\n\\n\\n\\n\\n...  \n",
       "1  \\n\\n\\n\\nAS I was saying, Sir, I have advanc'd ...  \n",
       "2  MARTIN and LUCETTA meeting.\\n\\n\\n\\nMR. Martin,...  \n",
       "3  \\n\\n\\n\\n\\nWELL, well, Aemilia, You may pre∣ten...  \n",
       "4  duke royal lecher go grey haired adultery \\nan...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "\n",
    "def create_dataframe_from_path(path):\n",
    "    \"\"\"\n",
    "    Searches the entire directory structure for textfiles\n",
    "    and stores the content in a pandas dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    data = []\n",
    "\n",
    "    filepaths = glob(path + \"/**/*.txt\", recursive=True)\n",
    "\n",
    "    for filepath in filepaths:\n",
    "\n",
    "        # list where we will store the relevant data for this text\n",
    "        text_data = []\n",
    "\n",
    "        filename = os.path.basename(filepath)\n",
    "        author = filename.split(\"-\")[0]\n",
    "        year = filename.split(\"-\")[1]\n",
    "        title = filename.split(\"-\")[2]\n",
    "\n",
    "        text = open(filepath, encoding=\"utf-8\").read()\n",
    "        file_data = {\n",
    "            \"file\": filename,\n",
    "            \"author\": author,\n",
    "            \"year\": year,\n",
    "            \"title\": title,\n",
    "            \"text\": text,\n",
    "        }\n",
    "\n",
    "        data.append(file_data)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "df = create_dataframe_from_path(TEXT_PATH)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to clean the text and create sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lowercase(input):\n",
    "    \"\"\"\n",
    "    This function takes a string with both lower and upper case elements and returns only lower case elements\n",
    "    \"\"\"\n",
    "    output = str(input).lower()\n",
    "    return output\n",
    "\n",
    "\n",
    "def text_to_sentences(input):\n",
    "    \"\"\"\n",
    "    divide text into sentences\n",
    "    \"\"\"\n",
    "    paragraph = re.sub(\"—\", \"\", input)\n",
    "\n",
    "    sentences = re.split(\"[.:,!?\\n]\", paragraph)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def clean_divide(text):\n",
    "    text = clean_lowercase(text)\n",
    "    sentences = text_to_sentences(text)\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the functions to clean the text and divide it in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CareyGeorge Saville-1770-Analects in verse an2...</td>\n",
       "      <td>CareyGeorge Saville</td>\n",
       "      <td>1770</td>\n",
       "      <td>Analects in verse an22.txt</td>\n",
       "      <td>[, , a room in brainly's house, , , , , , , , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CentlivreSusanna-1707-The platonick lady 26.txt</td>\n",
       "      <td>CentlivreSusanna</td>\n",
       "      <td>1707</td>\n",
       "      <td>The platonick lady 26.txt</td>\n",
       "      <td>[, , , , as i was saying,  sir,  i have advanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KingThomas-1769-Wit's last stake A 19.txt</td>\n",
       "      <td>KingThomas</td>\n",
       "      <td>1769</td>\n",
       "      <td>Wit's last stake A 19.txt</td>\n",
       "      <td>[martin and lucetta meeting, , , , , mr,  mart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PhilipsWilliam-1700-St StephensGreen 213.txt</td>\n",
       "      <td>PhilipsWilliam</td>\n",
       "      <td>1700</td>\n",
       "      <td>St StephensGreen 213.txt</td>\n",
       "      <td>[, , , , , well,  well,  aemilia,  you may pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Middleton Thomas-1606-The Revenger's Tragedy.txt</td>\n",
       "      <td>Middleton Thomas</td>\n",
       "      <td>1606</td>\n",
       "      <td>The Revenger's Tragedy.txt</td>\n",
       "      <td>[duke royal lecher go grey haired adultery , a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>MountfortWilliam-1688-The injur'd lovers 188.txt</td>\n",
       "      <td>MountfortWilliam</td>\n",
       "      <td>1688</td>\n",
       "      <td>The injur'd lovers 188.txt</td>\n",
       "      <td>[, , discovers the king lying on a couch; afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>PhilipsWilliam-1698-The revengeful queen214.txt</td>\n",
       "      <td>PhilipsWilliam</td>\n",
       "      <td>1698</td>\n",
       "      <td>The revengeful queen214.txt</td>\n",
       "      <td>[, , , , , how has longinus dar'd to offer thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>WilliamShakespeare-1593-Titus Andronicus.txt</td>\n",
       "      <td>WilliamShakespeare</td>\n",
       "      <td>1593</td>\n",
       "      <td>Titus Andronicus.txt</td>\n",
       "      <td>[, , , , andronicus and senators aloft,  and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>ShadwellThomas-1668-The sullen lovers o280.txt</td>\n",
       "      <td>ShadwellThomas</td>\n",
       "      <td>1668</td>\n",
       "      <td>The sullen lovers o280.txt</td>\n",
       "      <td>[, , , in what unlucky minute was i born, , to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>Shirley James-1629-The Grateful Servant.txt</td>\n",
       "      <td>Shirley James</td>\n",
       "      <td>1629</td>\n",
       "      <td>The Grateful Servant.txt</td>\n",
       "      <td>[the duke be move , , the news displease he mu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file               author  \\\n",
       "0    CareyGeorge Saville-1770-Analects in verse an2...  CareyGeorge Saville   \n",
       "1      CentlivreSusanna-1707-The platonick lady 26.txt     CentlivreSusanna   \n",
       "2            KingThomas-1769-Wit's last stake A 19.txt           KingThomas   \n",
       "3         PhilipsWilliam-1700-St StephensGreen 213.txt       PhilipsWilliam   \n",
       "4     Middleton Thomas-1606-The Revenger's Tragedy.txt     Middleton Thomas   \n",
       "..                                                 ...                  ...   \n",
       "927   MountfortWilliam-1688-The injur'd lovers 188.txt     MountfortWilliam   \n",
       "928    PhilipsWilliam-1698-The revengeful queen214.txt       PhilipsWilliam   \n",
       "929       WilliamShakespeare-1593-Titus Andronicus.txt   WilliamShakespeare   \n",
       "930     ShadwellThomas-1668-The sullen lovers o280.txt       ShadwellThomas   \n",
       "931        Shirley James-1629-The Grateful Servant.txt        Shirley James   \n",
       "\n",
       "     year                        title  \\\n",
       "0    1770   Analects in verse an22.txt   \n",
       "1    1707    The platonick lady 26.txt   \n",
       "2    1769    Wit's last stake A 19.txt   \n",
       "3    1700     St StephensGreen 213.txt   \n",
       "4    1606   The Revenger's Tragedy.txt   \n",
       "..    ...                          ...   \n",
       "927  1688   The injur'd lovers 188.txt   \n",
       "928  1698  The revengeful queen214.txt   \n",
       "929  1593         Titus Andronicus.txt   \n",
       "930  1668   The sullen lovers o280.txt   \n",
       "931  1629     The Grateful Servant.txt   \n",
       "\n",
       "                                                  text  \n",
       "0    [, , a room in brainly's house, , , , , , , , ...  \n",
       "1    [, , , , as i was saying,  sir,  i have advanc...  \n",
       "2    [martin and lucetta meeting, , , , , mr,  mart...  \n",
       "3    [, , , , , well,  well,  aemilia,  you may pre...  \n",
       "4    [duke royal lecher go grey haired adultery , a...  \n",
       "..                                                 ...  \n",
       "927  [, , discovers the king lying on a couch; afte...  \n",
       "928  [, , , , , how has longinus dar'd to offer thi...  \n",
       "929  [, , , , andronicus and senators aloft,  and t...  \n",
       "930  [, , , in what unlucky minute was i born, , to...  \n",
       "931  [the duke be move , , the news displease he mu...  \n",
       "\n",
       "[932 rows x 5 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2[\"text\"] = df2[\"text\"].apply(clean_divide)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another set of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_pos(text):\n",
    "    \"\"\"\n",
    "    This function tags words according to position of speech.\n",
    "    \"\"\"\n",
    "\n",
    "    ## Eliminate extra spaces\n",
    "    temp_list = word_tokenize(text)\n",
    "    # print(temp_list)\n",
    "    paragraph2 = \" \".join(temp_list)\n",
    "    # print(paragraph2)\n",
    "    nlp_sentence = tagger.tag_text(paragraph2)\n",
    "    # print(nlp_sentence)\n",
    "    return nlp_sentence\n",
    "\n",
    "\n",
    "def part_of_speech(input1):\n",
    "    global apply_counter1\n",
    "    tagged_sentences = []\n",
    "    for sentence in input1:\n",
    "        # print(sentence)\n",
    "        sentence2 = tag_pos(sentence)\n",
    "        # print(sentence2)\n",
    "        tagged_sentences += sentence2\n",
    "    apply_counter1 += 1\n",
    "    print(apply_counter1)\n",
    "    return tagged_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open tagger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">Clarify how tree-tagger should be downloaded for the 3 main OS.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "import treetaggerwrapper as ttpw\n",
    "\n",
    "\n",
    "if platform == \"darwin\":\n",
    "    tag_dir = \"./osfstorage-archive/Pipeline2.0 Frequencies/tree-tagger-MacOSX-3.2.3\"\n",
    "elif platform == \"win\":\n",
    "    tag_dir = \"./osfstorage-archive/Pipeline2.0 Frequencies/tree-tagger-windows-3.2.2/TreeTagger\"\n",
    "elif platform == \"linux\":\n",
    "    raise Exception(\"No tree-tragger available for platform \" + platform)\n",
    "else:\n",
    "    raise Exception(\"Unknown platform:\" + platform)\n",
    "\n",
    "tagger = ttpw.TreeTagger(\n",
    "    TAGLANG=\"en\",\n",
    "    TAGDIR=tag_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag the words in a sentence, relative to their POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "\n",
    "apply_counter1 = 0\n",
    "\n",
    "df3['text'] = df3['text'].apply(part_of_speech)\n",
    "\n",
    "df3.to_csv('1.1_output_preprocessed.csv', encoding='utf-8-sig')\n",
    "\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to filter words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words(sentence):\n",
    "    list1 = [\"love\", \"lover\", \"loving\", \"beloved\"]\n",
    "    list2 = [\"N\", \"J\"]\n",
    "\n",
    "    filtered_list = []\n",
    "    global apply_counter2\n",
    "    for item in sentence:\n",
    "        temp_list = item.split(\"\\t\")\n",
    "\n",
    "        lemma = temp_list[2]\n",
    "        pos = temp_list[1][:1]\n",
    "        # print(lemma, pos)\n",
    "\n",
    "        if (lemma not in stop_words) and (len(lemma) > 2):\n",
    "            if (pos in list2) or (lemma in list1):\n",
    "                filtered_list += [lemma]\n",
    "                # print(lemma, pos)\n",
    "    apply_counter2 += 1\n",
    "\n",
    "    print(apply_counter2)\n",
    "\n",
    "    return filtered_list\n",
    "\n",
    "\n",
    "# apply function\n",
    "df4 = df3.copy()\n",
    "apply_counter2 = 0\n",
    "df4['text'] = df4['text'].apply(filter_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to disk\n",
    "\n",
    "as `1.2_output_filtered.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.to_csv('1.2_output_filtered.csv', encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
