{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a717ea9a-d5ea-4d55-bea8-260a40e1076d",
   "metadata": {},
   "source": [
    "Assignment 3 - Diachronic analysis of movie dialogues\n",
    "===\n",
    "\n",
    "*Due: January 1 2023*\n",
    "\n",
    "In this assignment you will analyze how the expression of Hope in movie dialogues changed with time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c4f04c-b0ca-42ef-a96e-3839bcd32438",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2d76af2-250f-4b07-a889-b033fb948bca",
   "metadata": {},
   "source": [
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a66a017-7a31-460c-a74a-2fff691e7332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from itertools import compress\n",
    "\n",
    "\n",
    "layout = widgets.Layout(width=\"auto\")\n",
    "lang = \"eng\"\n",
    "data_path = \"data/dialogs_preprocessed2/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea52e22-c3ff-4f6d-a89b-12c6262efe35",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95f3c87e-4e4f-4ba1-8600-f0923cc2c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_list(seed_word, language):\n",
    "\n",
    "    ## we create an empty list to store the final word list\n",
    "    list_of_lemmas = []\n",
    "    list_of_meanings = []\n",
    "\n",
    "    ## a function to add a word to a list\n",
    "    add_to_list = lambda list1, item1: list1.append(item1)\n",
    "\n",
    "    ## a function to return the hyponyms of a synset\n",
    "    hypos = lambda s: s.hyponyms()\n",
    "\n",
    "    ## wn.synset obtains the list of synonyms and meanings for that word, in different syntactic categories\n",
    "    meanings = wn.synsets(seed_word, pos=wn.NOUN + wn.VERB + wn.ADJ)\n",
    "\n",
    "    ## loop over set of meanings in synset\n",
    "    for meaning in meanings:\n",
    "\n",
    "        ## add synset, definition, and a list of all associated lemmas into the list_of_meanings\n",
    "        list_of_meanings += [\n",
    "            [\n",
    "                meaning,\n",
    "                meaning.definition(),\n",
    "                [lemma.name() for lemma in meaning.lemmas(language)],\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        ## append all synonyms (lemmas()) of that meaning to the list_of_lemmas\n",
    "        [\n",
    "            add_to_list(list_of_lemmas, lemma.name())\n",
    "            for lemma in meaning.lemmas(language)\n",
    "        ]\n",
    "\n",
    "        ## loop over the list of all possible hyponyms\n",
    "        for hyponym in meaning.closure(hypos):\n",
    "\n",
    "            ## add synsets, definition, and a list of all associated lemmas into the list_of_meanings\n",
    "            list_of_meanings += [\n",
    "                [\n",
    "                    hyponym,\n",
    "                    hyponym.definition(),\n",
    "                    [lemma.name() for lemma in hyponym.lemmas(language)],\n",
    "                ]\n",
    "            ]\n",
    "\n",
    "            ## append all synonyms (lemmas()) of that hyponym to the list_of_lemmas\n",
    "            [\n",
    "                add_to_list(list_of_lemmas, lemma.name())\n",
    "                for lemma in hyponym.lemmas(language)\n",
    "            ]\n",
    "\n",
    "    ##eliminate list duplications by applying the set transformation\n",
    "    set_of_lemmas = [*set(list_of_lemmas)]\n",
    "\n",
    "    ## sort alphabetically\n",
    "    set_of_lemmas.sort()\n",
    "\n",
    "    ##length\n",
    "    length = len(set_of_lemmas)\n",
    "\n",
    "    return (set_of_lemmas, length, list_of_meanings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b785f-9684-40e5-8889-ebf4445ed480",
   "metadata": {},
   "source": [
    "## 0. Expression of interest: Hope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39dad581-fd7b-40e5-9fe6-3bb2bdbd18ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_word = \"hope\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceb5fae-a31f-4366-b5c0-28e022f84e5c",
   "metadata": {},
   "source": [
    "## 1. Control measure: Irritation\n",
    "\n",
    "Find control measure to contrast with \"Hope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e82b40c-d2eb-42d4-8673-148e1a204b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_seed_word = \"irritation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c6644d-9455-4e26-b1f1-d70891d552ce",
   "metadata": {},
   "source": [
    "## 2. Initial bags of seeds\n",
    "\n",
    "Find psychometric tools or equivalent to generate initial bags of seeds, for both Hope and the control condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6de92a90-55d3-4305-be65-b338ad64d84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of lemma list is 16\n"
     ]
    }
   ],
   "source": [
    "seed_list = generate_word_list(seed_word, lang)\n",
    "print(f\"Length of lemma list is {seed_list[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60bdecc2-4306-4b51-b2b2-74c6adc1eee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of lemma list is 29\n"
     ]
    }
   ],
   "source": [
    "ctrl_seed_list = generate_word_list(control_seed_word, lang)\n",
    "print(f\"Length of lemma list is {ctrl_seed_list[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957f916-3bd7-4849-857c-fbab3bb1b60f",
   "metadata": {},
   "source": [
    "## 3. Expand bag of seeds and get synonyms and hyponyms\n",
    "\n",
    "Use WordNet tools to expand your bag of seeds and get synonyms and hyponyms, and start excluding words with unrelated meanings using the filters available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c7cb75-0a2d-45ac-9d64-8d4c8b357be8",
   "metadata": {},
   "source": [
    "### Hope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4ac8433-af75-4810-a93d-47dbdfa67eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a10f4cea464df285824c8a8a8c22ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=True, description=\"[Synset('hope.n.01'), 'a specific instance of feeling hopeful…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selection_widget = widgets.VBox(\n",
    "    [\n",
    "        widgets.Checkbox(\n",
    "            value=True,\n",
    "            description=str(item),\n",
    "            disabled=False,\n",
    "            indent=False,\n",
    "            layout=layout,\n",
    "        )\n",
    "        for item in seed_list[2]\n",
    "    ]\n",
    ")\n",
    "\n",
    "selection_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecf67084-2bdd-4881-b063-4aaa30a010ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['desire', 'encouragement', 'go_for', 'great_white_hope', 'hope', 'hopefulness', 'optimism', 'promise', 'rainbow', 'sanguineness', 'sanguinity', 'trust', 'white_hope']\n"
     ]
    }
   ],
   "source": [
    "def prune_list(w, seed_list):\n",
    "    filtered_meanings = list(\n",
    "        compress(seed_list[2], [widget.value for widget in w.children])\n",
    "    )\n",
    "\n",
    "    ## now we extract just the lemmas\n",
    "    filtered_list = [word for lemmas in filtered_meanings for word in lemmas[2]]\n",
    "\n",
    "    ## eliminate duplications and sort alphabetically\n",
    "\n",
    "    filtered_list = sorted([*set(filtered_list)])\n",
    "\n",
    "    return filtered_list\n",
    "\n",
    "\n",
    "filtered_list = prune_list(selection_widget, seed_list)\n",
    "\n",
    "print(filtered_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3137d9-0c48-4cca-8d7b-d8a846e612b9",
   "metadata": {},
   "source": [
    "### Irritation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d094686c-080c-4994-84f1-299a239047e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810baeb8c4974687bb693272387faa4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=True, description=\"[Synset('irritation.n.01'), 'the psychological state of being…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ctrl_selection_widget = widgets.VBox(\n",
    "    [\n",
    "        widgets.Checkbox(\n",
    "            value=True,\n",
    "            description=str(item),\n",
    "            disabled=False,\n",
    "            indent=False,\n",
    "            layout=layout,\n",
    "        )\n",
    "        for item in ctrl_seed_list[2]\n",
    "    ]\n",
    ")\n",
    "\n",
    "ctrl_selection_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "89196891-0a0f-4da5-8eef-7f3c11f0ef1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annoyance', 'annoying', 'botheration', 'bummer', 'discomfort', 'exasperation', 'huff', 'impatience', 'irritation', 'last_straw', 'miff', 'pinprick', 'red_flag', 'restlessness', 'seeing_red', 'snit', 'soreness', 'taunt', 'taunting', 'twit', 'vexation']\n"
     ]
    }
   ],
   "source": [
    "ctrl_filtered_list = prune_list(ctrl_selection_widget, ctrl_seed_list)\n",
    "\n",
    "print(ctrl_filtered_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d49b4fc-fd8a-470a-aab8-e919a5def6d2",
   "metadata": {},
   "source": [
    "### Extend bag of words with new synonyms/hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04918777-e8b8-45fc-9598-eadfb7d104a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b376a7-4250-4b7a-ad75-5b7e5be69341",
   "metadata": {},
   "source": [
    "## 4. Train semantic vector space model\n",
    "\n",
    "Train a semantic vector space model using word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8789cfc-7e34-4f3f-a3db-43211ead41fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb3485b-43b7-48f4-b842-088287935746",
   "metadata": {},
   "source": [
    "## 5. Semantic clouds\n",
    "\n",
    "Use your vector space model to find out the semantic clouds of each word in your bag of seeds, and select only the words with semantically meaningful clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddca6110-2e4e-4b15-89cf-e79c847672b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a44741-d1a4-4dd3-af12-7a0850f5695f",
   "metadata": {},
   "source": [
    "## 6. Final bag of rods and word frequencies\n",
    "\n",
    "Take the final Bag of Words, prune it further if necessary, and use the second script to calculate word frequencies (don't forget to upload the text files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3640fc8-cb08-4011-ac7c-d97721423c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1775c265-894e-47d7-9b78-71d19c71e9ac",
   "metadata": {},
   "source": [
    "## 7. Relevant ratio, visualization of time series\n",
    "\n",
    "Calculate your psychological relevant ratio, build a dataframe and plot a time series using Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3537078-024a-45cc-a700-92f99a65f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
