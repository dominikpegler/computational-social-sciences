{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a717ea9a-d5ea-4d55-bea8-260a40e1076d",
   "metadata": {},
   "source": [
    "Assignment 3 - Diachronic analysis of movie dialogues\n",
    "===\n",
    "\n",
    "*Due: January 1 2023*\n",
    "\n",
    "In this assignment you will analyze how the expression of Hope in movie dialogues changed with time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c4f04c-b0ca-42ef-a96e-3839bcd32438",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2d76af2-250f-4b07-a889-b033fb948bca",
   "metadata": {},
   "source": [
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0a66a017-7a31-460c-a74a-2fff691e7332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import itertools\n",
    "\n",
    "\n",
    "layout = widgets.Layout(width=\"auto\")\n",
    "lang = \"eng\"\n",
    "data_path = \"data/dialogs_preprocessed2/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea52e22-c3ff-4f6d-a89b-12c6262efe35",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95f3c87e-4e4f-4ba1-8600-f0923cc2c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_list(seed_word, language):\n",
    "    \"\"\"\n",
    "    Takes in 1 seed word and returns\n",
    "    a word list, the length and a list of synsets\n",
    "    \"\"\"\n",
    "\n",
    "    ## we create an empty list to store the final word list\n",
    "    list_of_lemmas = []\n",
    "    list_of_meanings = []\n",
    "\n",
    "    ## a function to add a word to a list\n",
    "    add_to_list = lambda list1, item1: list1.append(item1)\n",
    "\n",
    "    ## a function to return the hyponyms of a synset\n",
    "    hypos = lambda s: s.hyponyms()\n",
    "\n",
    "    ## wn.synset obtains the list of synonyms and meanings for that word, in different syntactic categories\n",
    "    meanings = wn.synsets(seed_word, pos=wn.NOUN + wn.VERB + wn.ADJ)\n",
    "\n",
    "    ## loop over set of meanings in synset\n",
    "    for meaning in meanings:\n",
    "\n",
    "        ## add synset, definition, and a list of all associated lemmas into the list_of_meanings\n",
    "        list_of_meanings += [\n",
    "            [\n",
    "                meaning,\n",
    "                meaning.definition(),\n",
    "                [lemma.name() for lemma in meaning.lemmas(language)],\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        ## append all synonyms (lemmas()) of that meaning to the list_of_lemmas\n",
    "        [\n",
    "            add_to_list(list_of_lemmas, lemma.name())\n",
    "            for lemma in meaning.lemmas(language)\n",
    "        ]\n",
    "\n",
    "        ## loop over the list of all possible hyponyms\n",
    "        for hyponym in meaning.closure(hypos):\n",
    "\n",
    "            ## add synsets, definition, and a list of all associated lemmas into the list_of_meanings\n",
    "            list_of_meanings += [\n",
    "                [\n",
    "                    hyponym,\n",
    "                    hyponym.definition(),\n",
    "                    [lemma.name() for lemma in hyponym.lemmas(language)],\n",
    "                ]\n",
    "            ]\n",
    "\n",
    "            ## append all synonyms (lemmas()) of that hyponym to the list_of_lemmas\n",
    "            [\n",
    "                add_to_list(list_of_lemmas, lemma.name())\n",
    "                for lemma in hyponym.lemmas(language)\n",
    "            ]\n",
    "\n",
    "    ##eliminate list duplications by applying the set transformation\n",
    "    set_of_lemmas = [*set(list_of_lemmas)]\n",
    "\n",
    "    ## sort alphabetically\n",
    "    set_of_lemmas.sort()\n",
    "\n",
    "    ##length\n",
    "    length = len(set_of_lemmas)\n",
    "\n",
    "    return (set_of_lemmas, length, list_of_meanings)\n",
    "\n",
    "\n",
    "def prune_list(w, syn_list):\n",
    "    \"\"\"\n",
    "    Takes in a container checkbox widget,\n",
    "    a list with synsets and returns\n",
    "    a filtered word list.\n",
    "    \"\"\"\n",
    "\n",
    "    filtered_meanings = list(\n",
    "        itertools.compress(syn_list, [widget.value for widget in w.children])\n",
    "    )\n",
    "\n",
    "    filtered_list = [word for lemmas in filtered_meanings for word in lemmas[2]]\n",
    "\n",
    "    filtered_list = sorted([*set(filtered_list)])\n",
    "\n",
    "    return filtered_list\n",
    "\n",
    "\n",
    "def expand_meanings(seed_words, language):\n",
    "    \"\"\"\n",
    "    Takes in a list of seed words and returns all synsets.\n",
    "    \"\"\"\n",
    "\n",
    "    list_meanings = []\n",
    "\n",
    "    for sw in seed_words:\n",
    "        _, _, meanings = generate_word_list(sw, language)\n",
    "        list_meanings += meanings\n",
    "\n",
    "    list_meanings.sort()\n",
    "\n",
    "    # groupby also eliminates duplications\n",
    "    list(list_meanings for list_meanings, _ in itertools.groupby(list_meanings))\n",
    "\n",
    "    return list_meanings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b785f-9684-40e5-8889-ebf4445ed480",
   "metadata": {},
   "source": [
    "## 0. Expression of interest: Hope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39dad581-fd7b-40e5-9fe6-3bb2bdbd18ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_word = \"hope\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceb5fae-a31f-4366-b5c0-28e022f84e5c",
   "metadata": {},
   "source": [
    "## 1. Control measure: Irritation\n",
    "\n",
    "Find control measure to contrast with \"Hope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8e82b40c-d2eb-42d4-8673-148e1a204b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_seed_word = \"irritation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c6644d-9455-4e26-b1f1-d70891d552ce",
   "metadata": {},
   "source": [
    "## 2. Initial bags of seeds\n",
    "\n",
    "Find psychometric tools or equivalent to generate initial bags of seeds, for both Hope and the control condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6de92a90-55d3-4305-be65-b338ad64d84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of lemma list is 16\n"
     ]
    }
   ],
   "source": [
    "seed_list = generate_word_list(seed_word, lang)\n",
    "print(f\"Length of lemma list is {seed_list[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "60bdecc2-4306-4b51-b2b2-74c6adc1eee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of lemma list is 29\n"
     ]
    }
   ],
   "source": [
    "ctrl_seed_list = generate_word_list(control_seed_word, lang)\n",
    "print(f\"Length of lemma list is {ctrl_seed_list[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957f916-3bd7-4849-857c-fbab3bb1b60f",
   "metadata": {},
   "source": [
    "## 3. Expand bag of seeds and get synonyms and hyponyms\n",
    "\n",
    "Use WordNet tools to expand your bag of seeds and get synonyms and hyponyms, and start excluding words with unrelated meanings using the filters available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c7cb75-0a2d-45ac-9d64-8d4c8b357be8",
   "metadata": {},
   "source": [
    "### Hope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e4ac8433-af75-4810-a93d-47dbdfa67eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c4d52218f94997863146467f8a825c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=True, description=\"[Synset('hope.n.01'), 'a specific instance of feeling hopeful…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selection_widget = widgets.VBox(\n",
    "    [\n",
    "        widgets.Checkbox(\n",
    "            value=True,\n",
    "            description=str(item),\n",
    "            disabled=False,\n",
    "            indent=False,\n",
    "            layout=layout,\n",
    "        )\n",
    "        for item in seed_list[2]\n",
    "    ]\n",
    ")\n",
    "\n",
    "selection_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ecf67084-2bdd-4881-b063-4aaa30a010ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['desire', 'encouragement', 'go_for', 'great_white_hope', 'hope', 'hopefulness', 'optimism', 'promise', 'rainbow', 'sanguineness', 'sanguinity', 'trust', 'white_hope']\n"
     ]
    }
   ],
   "source": [
    "seed_words = prune_list(selection_widget, seed_list[2])\n",
    "\n",
    "print(seed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88eead8-5666-4925-bcd2-a86b532af393",
   "metadata": {},
   "source": [
    "#### Extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b5d81585-685f-4079-8cc9-ddb87281d048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synsets = expand_meanings(seed_words, lang)\n",
    "len(synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c493ba2f-d55a-409d-b354-2ead1b402b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Synset('abetment.n.01'),\n",
       "  'the verbal act of urging on',\n",
       "  ['abetment', 'abettal', 'instigation']],\n",
       " [Synset('accept.v.03'),\n",
       "  'give an affirmative reply to; respond favorably to',\n",
       "  ['accept', 'consent', 'go_for']],\n",
       " [Synset('accept.v.07'),\n",
       "  'tolerate or accommodate oneself to',\n",
       "  ['accept', 'live_with', 'swallow']],\n",
       " [Synset('accredit.v.01'),\n",
       "  'grant credentials to',\n",
       "  ['accredit', 'recognize', 'recognise']],\n",
       " [Synset('ache.v.02'),\n",
       "  'have a desire for something or someone who is not present',\n",
       "  ['ache', 'yearn', 'yen', 'pine', 'languish']]]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synsets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3137d9-0c48-4cca-8d7b-d8a846e612b9",
   "metadata": {},
   "source": [
    "### Irritation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d094686c-080c-4994-84f1-299a239047e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6866f7b65c4a37ba4398e8e33c71a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=True, description=\"[Synset('irritation.n.01'), 'the psychological state of being…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ctrl_selection_widget = widgets.VBox(\n",
    "    [\n",
    "        widgets.Checkbox(\n",
    "            value=True,\n",
    "            description=str(item),\n",
    "            disabled=False,\n",
    "            indent=False,\n",
    "            layout=layout,\n",
    "        )\n",
    "        for item in ctrl_seed_list[2]\n",
    "    ]\n",
    ")\n",
    "\n",
    "ctrl_selection_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "89196891-0a0f-4da5-8eef-7f3c11f0ef1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aggravation', 'aggro', 'annoyance', 'annoying', 'botheration', 'bummer', 'discomfort', 'exacerbation', 'exasperation', 'excitation', 'huff', 'impatience', 'innervation', 'irritation', 'last_straw', 'miff', 'pinprick', 'pique', 'provocation', 'red_flag', 'restlessness', 'seeing_red', 'snit', 'soreness', 'taunt', 'taunting', 'temper', 'twit', 'vexation']\n"
     ]
    }
   ],
   "source": [
    "ctrl_seed_words = prune_list(ctrl_selection_widget, ctrl_seed_list[2])\n",
    "\n",
    "print(ctrl_seed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d49b4fc-fd8a-470a-aab8-e919a5def6d2",
   "metadata": {},
   "source": [
    "#### Extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fa501637-8bcb-47bf-aaa5-1f579c8b59f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrl_synsets = expand_meanings(ctrl_seed_words, lang)\n",
    "len(ctrl_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "40712a7c-4ea5-43c2-993a-71aa3eb536e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Synset('abatable_nuisance.n.01'),\n",
       "  'a nuisance that can remedied (suppressed or extinguished or rendered harmless)',\n",
       "  ['abatable_nuisance']],\n",
       " [Synset('abatable_nuisance.n.01'),\n",
       "  'a nuisance that can remedied (suppressed or extinguished or rendered harmless)',\n",
       "  ['abatable_nuisance']],\n",
       " [Synset('aggravation.n.01'),\n",
       "  'an exasperated feeling of annoyance',\n",
       "  ['aggravation', 'exasperation']],\n",
       " [Synset('aggravation.n.01'),\n",
       "  'an exasperated feeling of annoyance',\n",
       "  ['aggravation', 'exasperation']],\n",
       " [Synset('aggravation.n.01'),\n",
       "  'an exasperated feeling of annoyance',\n",
       "  ['aggravation', 'exasperation']]]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrl_synsets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b376a7-4250-4b7a-ad75-5b7e5be69341",
   "metadata": {},
   "source": [
    "## 4. Train semantic vector space model\n",
    "\n",
    "Train a semantic vector space model using word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8789cfc-7e34-4f3f-a3db-43211ead41fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb3485b-43b7-48f4-b842-088287935746",
   "metadata": {},
   "source": [
    "## 5. Semantic clouds\n",
    "\n",
    "Use your vector space model to find out the semantic clouds of each word in your bag of seeds, and select only the words with semantically meaningful clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddca6110-2e4e-4b15-89cf-e79c847672b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a44741-d1a4-4dd3-af12-7a0850f5695f",
   "metadata": {},
   "source": [
    "## 6. Final bag of rods and word frequencies\n",
    "\n",
    "Take the final Bag of Words, prune it further if necessary, and use the second script to calculate word frequencies (don't forget to upload the text files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3640fc8-cb08-4011-ac7c-d97721423c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1775c265-894e-47d7-9b78-71d19c71e9ac",
   "metadata": {},
   "source": [
    "## 7. Relevant ratio, visualization of time series\n",
    "\n",
    "Calculate your psychological relevant ratio, build a dataframe and plot a time series using Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3537078-024a-45cc-a700-92f99a65f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
