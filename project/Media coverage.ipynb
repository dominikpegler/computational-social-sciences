{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2ebc25-2803-4203-94f7-2fbc0792bba5",
   "metadata": {},
   "source": [
    "Analyzing Media Coverage Of Other Countries in Austria\n",
    "===\n",
    "\n",
    "\n",
    "The aim of this project is to find out how reporting in Austria's print media about certain countries has changed over time (sentiment, which topics). In two further steps, I would also like to go down to the level of the individual newspapers and their authors and take an explorative look at whether there are tendencies/bias here. As countries of interest I choose Balkan countries because of their proximity to Austria and their long history of conflict.\n",
    "\n",
    "    Text corpora: Austrian newspaper articles (or their respective twitter posts)\n",
    "    Language: German\n",
    "    Time: 2000–2022\n",
    "    Method: Adding country labels to the articles, Sentiment Scores (, extracting underlying topics of the articles, e.g. with fuzzy topic modeling) \n",
    "    \n",
    "According to https://de.wikipedia.org/wiki/Liste_%C3%B6sterreichischer_Zeitungen_und_Zeitschriften derstandard.at and krone.at reach the most people online, they also cover Austrian society quite well. So, initially, I will focus on these two and might add some more newspapers at a later stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081e0c21-e47d-40aa-9380-68ee2f79db70",
   "metadata": {},
   "source": [
    "* Focus on 2 countries: Serbia and Croatia (like Austria now a EU country)\n",
    "* I will label an article with \"Serbia\" if the ratio of amount of words that relate to \"Serbia\"  compared to words that relate to \"Croatia\" is greater than 4\n",
    "* I will also try to find out if there are certain authors who are responsible for a certain tendency.\n",
    "* Another analysis could be build upon the ratio of \"Serbia\" and \"Albania\" or \"Kosovo\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eec6929b-dce0-4b83-9ca8-604f4cb90b92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e94fe83f-5986-4487-87b0-69c28beffad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data_dir = \"data/twitter\"\n",
    "\n",
    "if os.path.exists(data_dir) == False:\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "\n",
    "def dl_user(user, max_results=None, local=False):\n",
    "    \"\"\"\n",
    "    Function to download tweets by username.\n",
    "    Set local to True, if tweets have already\n",
    "    been downloaded and are available in data_dir.\n",
    "\n",
    "    Returns a DataFrame.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if local == False:\n",
    "        with open(data_dir + f\"/user-{user}.json\", \"w+\") as fo:\n",
    "            if max_results == None:\n",
    "                cmd_list = [\"snscrape\", \"--jsonl\", \"twitter-user\", user]\n",
    "            else:\n",
    "                cmd_list = [\n",
    "                    \"snscrape\",\n",
    "                    \"--jsonl\",\n",
    "                    \"-n \" + str(max_results),\n",
    "                    \"twitter-user\",\n",
    "                    user,\n",
    "                ]\n",
    "            p = subprocess.Popen(cmd_list, stdout=fo)\n",
    "            p.wait()\n",
    "\n",
    "    with open(data_dir + f\"/user-{user}.json\", \"r\") as fo:\n",
    "        tweets = fo.readlines()\n",
    "\n",
    "    tweets = [json.loads(tweets[i]) for i in range(0, len(tweets))]\n",
    "    print(\"loaded\", len(tweets), \"tweets\\n\")\n",
    "\n",
    "    df_tweets = pd.DataFrame(tweets)\n",
    "    df_tweets[\"date\"] = pd.to_datetime(df_tweets[\"date\"])\n",
    "\n",
    "    return df_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e241f950-b2f3-4d09-afd5-7f97137af3f3",
   "metadata": {},
   "source": [
    "# 1. Scraping newspaper articles\n",
    "\n",
    "## 1.1. derStandard.at\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81c012de-9c75-4cf2-8645-5d26f9e466f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 272221 tweets\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rawContent</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-24 20:00:04+00:00</td>\n",
       "      <td>Kantersieg für Leipzig gegen Schalke:  https:/...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-24 19:31:27+00:00</td>\n",
       "      <td>Mordverdacht in Mürzzuschlag: Frau tödlich ver...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-24 18:57:26+00:00</td>\n",
       "      <td>Welche Laufgruppen gibt es in Wien?:  https://...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-24 18:57:25+00:00</td>\n",
       "      <td>Gleichberechtigung beim Dating: Bumble-Gründer...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-24 18:43:22+00:00</td>\n",
       "      <td>Aigner und Edlinger holen Gold bei Para-WM:  h...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  \\\n",
       "0 2023-01-24 20:00:04+00:00   \n",
       "1 2023-01-24 19:31:27+00:00   \n",
       "2 2023-01-24 18:57:26+00:00   \n",
       "3 2023-01-24 18:57:25+00:00   \n",
       "4 2023-01-24 18:43:22+00:00   \n",
       "\n",
       "                                          rawContent hashtags  \n",
       "0  Kantersieg für Leipzig gegen Schalke:  https:/...     None  \n",
       "1  Mordverdacht in Mürzzuschlag: Frau tödlich ver...     None  \n",
       "2  Welche Laufgruppen gibt es in Wien?:  https://...     None  \n",
       "3  Gleichberechtigung beim Dating: Bumble-Gründer...     None  \n",
       "4  Aigner und Edlinger holen Gold bei Para-WM:  h...     None  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = dl_user(\n",
    "    \"derstandardat\", max_results=None, local=True\n",
    ")  # max_results=None for all (default)\n",
    "\n",
    "# print the first 5\n",
    "df_tweets[[\"date\", \"rawContent\", \"hashtags\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86e4213c-9cbf-48e2-b42f-fbd1f829f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tewee"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
