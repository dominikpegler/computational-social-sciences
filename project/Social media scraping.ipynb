{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6e9f5a-f7e1-4d46-bdaa-c1b51585ce8e",
   "metadata": {},
   "source": [
    "Social media scraping\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd21ee82-8fd4-4c0f-bf38-37cab1108235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "\n",
    "data_dir = \"data/twitter\"\n",
    "\n",
    "if os.path.exists(data_dir) == False:\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b0c0f1-67cd-4491-8901-0330b8dbddf7",
   "metadata": {},
   "source": [
    "## Tweets by User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b68b13-8303-475b-b21a-dac0a1d16e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_user(user, max_results, local=False):\n",
    "    \"\"\"\n",
    "    Function to download tweets by username.\n",
    "    Set local to True, if tweets have already\n",
    "    been downloaded and are available in data_dir.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if local==False:\n",
    "        with open(data_dir + f\"/user-{user}.json\", \"w+\") as fo:\n",
    "            p = subprocess.Popen(\n",
    "                [\"snscrape\", \"--jsonl\", max_results, \"twitter-user\", user], stdout=fo\n",
    "            )\n",
    "            p.wait()\n",
    "            \n",
    "    with open(data_dir+f\"/user-{user}.json\", \"r\") as fo:\n",
    "        tweets = fo.readlines()\n",
    "\n",
    "    tweets = [json.loads(tweets[i]) for i in range(0, len(tweets))]\n",
    "    print(\"loaded\", len(tweets), \"tweets\\n\")\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d913f65b-3daf-480a-94ad-035d4eb8b5ca",
   "metadata": {},
   "source": [
    "Scrape the last 100 tweets from `@derstandard` and store in json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a19df21c-a13d-4e28-b349-422754a9b31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 100 tweets\n",
      "\n",
      "2023-01-22T19:49:33+00:00 XSudoku mittel 5422b:  https://t.co/JpypjJAZiU None\n",
      "2023-01-22T19:17:17+00:00 Uhrmacher: \"Die Kundschaft glaubt, mir die Arbeit erklären zu müssen\":  https://t.co/XgBdv9G5Qs None\n",
      "2023-01-22T18:02:02+00:00 Weiterarbeiten im Pensionsalter: \"Meine Arbeit ist mein Leben\":  https://t.co/C1zpXtuZ9j None\n",
      "2023-01-22T18:02:01+00:00 Ältere sollen die Joblücke füllen. Aber wer will sie wirklich haben?:  https://t.co/a0yvyd7NAQ None\n",
      "2023-01-22T17:31:23+00:00 Julian Schütter: Kitzbühel-Opfer und Skifahrer for Future:  https://t.co/YEY11CcFhs None\n"
     ]
    }
   ],
   "source": [
    "tweets = dl_user(\"derstandardat\", \"-n 100\")  # \"\" for all, \"-n 100\" for 100\n",
    "\n",
    "\n",
    "# print the first 5\n",
    "for i in range(min(5, len(tweets))):\n",
    "    print(tweets[i][\"date\"], tweets[i][\"rawContent\"], tweets[i][\"hashtags\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c83eac-718a-49b8-9e0e-d42f253c009d",
   "metadata": {},
   "source": [
    "## Tweets by Hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5004933c-5da1-4881-9e3b-eee04ecd6252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_hashtag(hashtag, max_results, local=False):\n",
    "    \"\"\"\n",
    "    Function to download tweets by hashtag.\n",
    "    Set local to True, if tweets have already\n",
    "    been downloaded and are available in data_dir.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if local==False:\n",
    "        with open(data_dir + f\"/hashtag-{hashtag}.json\", \"w+\") as fo:\n",
    "            p = subprocess.Popen(\n",
    "                [\"snscrape\", \"--jsonl\", max_results, \"twitter-hashtag\", hashtag], stdout=fo\n",
    "            )\n",
    "            p.wait()\n",
    "            \n",
    "    with open(data_dir+f\"/hashtag-{hashtag}.json\", \"r\") as fo:\n",
    "        tweets = fo.readlines()\n",
    "\n",
    "    tweets = [json.loads(tweets[i]) for i in range(0, len(tweets))]\n",
    "    print(\"loaded\", len(tweets), \"tweets\\n\")\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eab29f-efe6-49da-978c-02498267add0",
   "metadata": {},
   "source": [
    "Scrape the last 100 tweets with `#chinesevirus` and store in json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b6e08-9467-4875-acdc-c67f67c46379",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = dl_hashtag(\"chinesevirus\", \"-n 100\")  # \"\" for all, \"-n 100\" for 100\n",
    "\n",
    "\n",
    "# print the first 5\n",
    "for i in range(min(5, len(tweets))):\n",
    "    print(tweets[i][\"date\"], tweets[i][\"rawContent\"], tweets[i][\"hashtags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27f79835-af01-4cd1-a022-4e90b1bfc968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 100 tweets\n",
      "\n",
      "2023-01-22T20:52:27+00:00 Gestern in der Sauna. \n",
      "Bin ja  als #Ungeimpfter jeden weiteren Tag entspannter und gelassener. \n",
      "Wenn aber ein Honk behauptet, dass die #Plandemie nur deswegen so massiv war, weil die #Ungeimpften die #Geimpften infiziert haben, kann ich nicht anders als zu reagieren. ['Ungeimpfter', 'Plandemie', 'Ungeimpften', 'Geimpften']\n",
      "2023-01-22T20:39:46+00:00 #LucMontagnier #VIH #Covid\n",
      "#Plandemic #plandemia #plandemie #plandemi https://t.co/HwILgcTnNS ['LucMontagnier', 'VIH', 'Covid', 'Plandemic', 'plandemia', 'plandemie', 'plandemi']\n",
      "2023-01-22T20:39:06+00:00 Diesem Mann sollte man zuhören. Er hat die Farce der #Schweinegrippe bereits durchschaut. Mit ihm als #Gesundheitsminister hätte es die #PLANdemie niemals gegeben. Lest auch sein Buch: Falsche Pandemien. #Wodarg #LongCovid #Impfschäden ['Schweinegrippe', 'Gesundheitsminister', 'PLANdemie', 'Wodarg', 'LongCovid', 'Impfschäden']\n",
      "2023-01-22T18:12:12+00:00 Ein #Vorteil der #Corona-#Plandemie ist es, dass viele am #Anfang der #Woche garantiert zu ihrem #Spaziergang an der frischen #Luft kommen.\n",
      "#Gesundheit #NatürlichesImmunsystem ['Vorteil', 'Corona', 'Plandemie', 'Anfang', 'Woche', 'Spaziergang', 'Luft', 'Gesundheit', 'NatürlichesImmunsystem']\n",
      "2023-01-22T17:32:31+00:00 #Afrika ist der große Gewinner der #Corona-#Plandemie. Deswegen versuchen sie beim nächsten letzten #Anlauf, auch diesen #Kontinent in den #Griff zu bekommen. Sie werden #scheitern.\n",
      "\"#Impfung\" #Pandemievertrag #WHO #WEF #BigPharma ['Afrika', 'Corona', 'Plandemie', 'Anlauf', 'Kontinent', 'Griff', 'scheitern', 'Impfung', 'Pandemievertrag', 'WHO', 'WEF', 'BigPharma']\n"
     ]
    }
   ],
   "source": [
    "tweets = dl_hashtag(\"plandemie\", \"-n 100\")  # \"\" for all, \"-n 100\" for 100\n",
    "\n",
    "\n",
    "# print the first 5\n",
    "for i in range(min(5, len(tweets))):\n",
    "    print(tweets[i][\"date\"], tweets[i][\"rawContent\"], tweets[i][\"hashtags\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8380fdfd-7d75-427c-8c83-34fdce53167a",
   "metadata": {},
   "source": [
    "All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a759d5-7093-44be-872f-6cd5e6fa35c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = dl_hashtag(\"plandemic\", \"-n 100\")  # \"\" for all, \"-n 100\" for 100\n",
    "\n",
    "\n",
    "# print the first 5\n",
    "for i in range(min(5, len(tweets))):\n",
    "    print(tweets[i][\"date\"], tweets[i][\"rawContent\"], tweets[i][\"hashtags\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
